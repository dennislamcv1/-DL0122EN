{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/qo20b88v1hbjztubt06609ovs85q8fau.png\" width=\"400px\" align=\"center\"></a>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Project: Character Modeling</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<font size=\"3\"><strong>In this notebook you will use TensorFlow to create a Recurrent Neural Network, to predict the next character in a string. You need to train your network using a CPU and using a GPU and benchmark the result to see which which device You have to write your code in empty cells in this notebook to make it complete, and then submit the notebook for peer-review.</strong></font>\n",
    "\n",
    "<h2>Table of Contents</h2>\n",
    "<ul>\n",
    "    <li><a href=\"#intro\">Introduction</a></li>\n",
    "    <li><a href=\"#lstm\">Long Short-Term Memory Model (LSTM) Architectures</a></li>\n",
    "    <li><a href=\"#cpu_vs_gpu\">Train your model using CPU and GPU</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#question_1\">Question 1: Complete the code to run it on CPU</a></li>\n",
    "            <li><a href=\"#question_2\">Question 2: Complete the code to run it on GPU</a></li>\n",
    "            <li><a href=\"#question_3\">Question 3: Compare the results</a></li>\n",
    "        </ol>    \n",
    "    </li>\n",
    "</ul>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"intro\"></a>\n",
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>This code is supposed to implement a Recurrent Neural Network with LSTM units for training/sampling from character-level language models. In other words, the model takes a text file as input and trains the RNN network that learns to predict the next character in a sequence.</p>  \n",
    "The RNN can then be used to generate text character by character that will look like the original training data. \n",
    "\n",
    "<p>This code is based on this <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">blog</a>, and the code is an step-by-step implementation of the <a href=\"https://github.com/crazydonkey200/tensorflow-char-rnn\">character-level implimentation</a>.</p>\n",
    "\n",
    "<p>I recommend you to complete the \"<a href=\"https://www.edx.org/course/deep-learning-with-tensorflow\">Deep Learning with TensorFlow</a>\" course for this project.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, lets import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import codecs\n",
    "import os\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Libraries\n",
    "<ul>\n",
    "    <li><b>os</b>: is an module that allows us to interact with the operating systerm, in particular we will use it to set the path in which we will be storing our input file, tensor file and vocab file</li>\n",
    "    <li><b>time</b>: is a library that allows us to access the clock time of our machine, we will use it to measure the performance of training our model with a CPU, versus training our model with a GPU</li>\n",
    "    <li><b>cPickle</b>: is a library for serializing and deserializing python objects, we will use the <b>dump()</b> method in cPickle to serialize our objects when saving them, and <b>load()</b> method in cPickle to deserialize our objects when loading.</li>\n",
    "    <li><b>codec</b>: is a library that deals with character encoding, we will use the <b>open()</b> method as it is recommended when opening encoded text files.</li>\n",
    "    <li><b>collections</b>: is a library that implements high performance container types, we will use the <b>Counter</b> object to get a collection of frequencies for our characters</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>Downloading the input data</h3>\n",
    "Lets download the input file, and take a look at some parts of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-08 07:11:23 URL:https://public.boxcloud.com/d/1/b1!uu2hGbk7uyMAq510frRGt3aBsBjarKEXEh25cywcAsxxXAdQr-2dKr7fbT5kguD32YXuX1YmTYXvZHp7mVqgnL6AEH2d3alE5j2yZ7aBsDkD-TV1khh9zSp_peqrjGdj62TQC3jvu1B9639UOOxFpqfWYPIXMgeMelZS_Hux1b8b_AQWgCFHxIF800X3aYfaN9AUow5v6cKXXkpyR8VDUhXONpdiU6WUclNW9KuHqOKcIxokBv37f6xMzvUr4aRFZBqdS-jd6BV907hThPYexXi5VXlOzBmL0A4s1ucUAEsBT1LOYN24w6Rp7BfjNhsfU1W2MIjRqwjPeRHzWyacr5ZOUIAuMSm7bO9is3kIljmglQ3ZgTe4WfW487CgnfJre6XGM8AsJV72S66gJDm4dsmKZIq8UuYv6iyjEIdEdPINIKLxH7hAGA1MIX9C-gZVNO2h5YVHACrc5iRQvMGSLaxf_2QtzKBBb77P9gXRHNcm4bQf47afumgasPLED5OnCanMeb-M8QoWPTG-5I85sFI9l4025R639vVXY62TWLQ3BmTMvPxOm7Rmxlcc0n_BMr68lwvAIsMUAa4j4hNfgRYS4vpQ6uhR1v9EwsJfeHmvKydIGjhjwRz2XRHDN7fMLEco8t4SI_HHagUGtJ_3Bn0vqMOibyXsqlw_kIutupvEyIvmMSrlVnXJvBAHGejKFNt9sVxxWE-xe3zOwaWC4dG0asyAv5A6qQQfqtU4B0GOPNrs4KPvaumwcc73zb66cQLj55QEmjlG5e47G4ziH0Z2bepc-Rsbh9JF8Jfy3bGvS89DU_HqxNTRVySTLvdcm0o2Pv_WBGUTSdgtN6PhHkqGTtLy1CyOVgrb_IDKfs3d6LpNPtITYY1_EbJP34PSvKhG7h-R4wyJy-Hu7YJgcGJ6s3_Im_JzobaCovinjcc4q6WBwzgqeUNKpnN5BM-P2347k8258It6VDcHNjMLanbPJXU-n-HQM27zF7Ax9-p7G72O565p-a_uuF27DMacpJAazZK45cW42vlRH5_sEtnx-Nz2NJH3Fks3NTQXr1RL9c57FTuYimsHi4aAg8NAyxO7HIX18pmmpfgRp4N6ty51Ljj_x4s-Yd0RFibhk8aeXOMWRwonryVYVIJ4yJpWOT0cI3m24vJa0qvEkWmgzSLyAGoUv0CD6fy8uwBgwRXVoWL4pRQ-C6TWzK0gr1QEDmm5ZzINDPRtXm05dt_ldOk7eIaeEyyo7-Ww7F1stfke6f7fKkPgFYQw9we7SJ5tvSaYJ24HxcdSVVNX6sDWGicyD-WcbphSfUIbPthvjkIHrYZwfiJJh7sgBZZDqMHHVqUpdcI5STlNEfHw31Rw9stD_3Kh7IjA7Jg5x5RlsO58zw../download [1115393/1115393] -> \"input.txt\" [1]\n",
      "-------------Sample text---------------\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -nv -O input.txt https://ibm.box.com/shared/static/a3f9e9mbpup09toq35ut7ke3l3lf03hg.txt \n",
    "with open('input.txt', 'r') as f:\n",
    "    read_data = f.read()\n",
    "    print(\"-------------Sample text---------------\")\n",
    "    print (read_data[0:500])\n",
    "    print(\"---------------------------------------\")\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>Data loader</h3>\n",
    "You need to read the input file and convert each character to numerical values. The following cell is a class that helps to read data from input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class TextLoader():\n",
    "    def __init__(self, data_dir, batch_size, seq_length, encoding='utf-8'):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.encoding = encoding\n",
    "\n",
    "        input_file = os.path.join(data_dir, \"input.txt\")\n",
    "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "\n",
    "        if not (os.path.exists(vocab_file) and os.path.exists(tensor_file)):\n",
    "            print(\"reading text file\")\n",
    "            self.preprocess(input_file, vocab_file, tensor_file)\n",
    "        else:\n",
    "            print(\"loading preprocessed files\")\n",
    "            self.load_preprocessed(vocab_file, tensor_file)\n",
    "        self.create_batches()\n",
    "        self.reset_batch_pointer()\n",
    "\n",
    "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
    "        with codecs.open(input_file, \"r\", encoding=self.encoding) as f:\n",
    "            data = f.read()\n",
    "        counter = collections.Counter(data)\n",
    "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "        self.chars, _ = zip(*count_pairs)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            cPickle.dump(self.chars, f)\n",
    "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
    "        np.save(tensor_file, self.tensor)\n",
    "\n",
    "    def load_preprocessed(self, vocab_file, tensor_file):\n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            self.chars = cPickle.load(f)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.tensor = np.load(tensor_file)\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "\n",
    "    def create_batches(self):\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "\n",
    "        # When the data (tensor) is too small, let's give them a better error message\n",
    "        if self.num_batches==0:\n",
    "            assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
    "\n",
    "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
    "        xdata = self.tensor\n",
    "        ydata = np.copy(self.tensor)\n",
    "        ydata[:-1] = xdata[1:]\n",
    "        ydata[-1] = xdata[0]\n",
    "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "\n",
    "\n",
    "    def next_batch(self):\n",
    "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x, y\n",
    "\n",
    "    def reset_batch_pointer(self):\n",
    "        self.pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>Parameters</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>We have to convert the characters in the string to numbers. Also we need to represent each sequence of characters as a vector in each batch.</p>\n",
    "So, let's set some parameters that we need those now for reading the dataset, and later to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "seq_length = 50 # RNN sequence length\n",
    "batch_size = 128  # minibatch size, i.e. size of data in each epoch\n",
    "num_epochs = 20 # you should change it to 50 if you want to see a relatively good results\n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "rnn_size = 128 # size of RNN hidden state (output dimension)\n",
    "num_layers = 2 #number of layers in the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>Now, we can read the data at batches using the <b>TextLoader</b> class. It will convert the characters to numbers, and represent each sequence as a vector in batches:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n",
      "vocabulary size: 65\n",
      "Characters: (' ', 'e', 't', 'o', 'a', 'h', 's', 'r', 'n', 'i', '\\n', 'l', 'd', 'u', 'm', 'y', ',', 'w', 'f', 'c', 'g', 'I', 'b', 'p', ':', '.', 'A', 'v', 'k', 'T', \"'\", 'E', 'O', 'N', 'R', 'S', 'L', 'C', ';', 'W', 'U', 'H', 'M', 'B', '?', 'G', '!', 'D', '-', 'F', 'Y', 'P', 'K', 'V', 'j', 'q', 'x', 'z', 'J', 'Q', 'Z', 'X', '3', '&', '$')\n",
      "vocab number of 'F': 49\n",
      "Character sequences (first batch): [[49  9  7 ...  1  4  7]\n",
      " [39  5  3 ...  0 20  9]\n",
      " [ 0  5  9 ... 19  4 13]\n",
      " ...\n",
      " [ 3 18 18 ...  1  0 23]\n",
      " [ 7  1 23 ... 18  3  7]\n",
      " [47 26 24 ...  0  8  3]]\n"
     ]
    }
   ],
   "source": [
    "data_loader = TextLoader('', batch_size, seq_length)\n",
    "vocab_size = data_loader.vocab_size\n",
    "print (\"vocabulary size:\" ,data_loader.vocab_size)\n",
    "print (\"Characters:\" ,data_loader.chars)\n",
    "print (\"vocab number of 'F':\",data_loader.vocab['F'])\n",
    "print (\"Character sequences (first batch):\", data_loader.x_batches[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<b>Notice:</b> In the following cells, we just go through the process of defining each element of the LSTM, and explore the inputs, outputs of each layer. Then, we put all together and run the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>1- Input and Output</h3>\n",
    "In the next cell we just take a look at a sample batch to underestand the data better. Each batch includes the input, <b>x</b>, and the character that we want to predict, <b>y</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [39,  5,  3, ...,  0, 20,  9],\n",
       "       [ 0,  5,  9, ..., 19,  4, 13],\n",
       "       ...,\n",
       "       [ 3, 18, 18, ...,  1,  0, 23],\n",
       "       [ 7,  1, 23, ..., 18,  3,  7],\n",
       "       [47, 26, 24, ...,  0,  8,  3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_loader.next_batch()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  #batch_size =128, seq_length=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, __y__ is the next character for each character in __x__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  7,  6, ...,  4,  7,  0],\n",
       "       [ 5,  3,  0, ..., 20,  9, 27],\n",
       "       [ 5,  9, 14, ...,  4, 13, 20],\n",
       "       ...,\n",
       "       [18, 18,  9, ...,  0, 23, 11],\n",
       "       [ 1, 23,  3, ...,  3,  7,  0],\n",
       "       [26, 24, 10, ...,  8,  3,  2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"lstm\"></a>\n",
    "<h3>2- What is Long Short-Term Memory Model (LSTM)?</h3>\n",
    "\n",
    "<p>Recurrent Neural Networks are Deep Learning models with simple structures and a feedback mechanism built-in, or in different words, the output of a layer is added to the next input and fed back to the same layer.</p>\n",
    "\n",
    "<p>The Recurrent Neural Network is a specialized type of Neural Network that solves the issue of <b>maintaining context for Sequential data</b> -- such as Weather data, Stocks, Genes, etc. At each iterative step, the processing unit takes in an input and the current state of the network, and produces an output and a new state that is <b>re-fed into the network</b>.</p>\n",
    "\n",
    "<p>However, <b>this model has some problems</b>. It's very computationally expensive to maintain the state for a large amount of units, even more so over a long amount of time. Additionally, Recurrent Networks are very sensitive to changes in their parameters. To solve these problems, we use a specific type of RNN, is called Long Short-Term Memory (LSTM).</p>\n",
    "\n",
    "\n",
    "Each LSTM cell has 5 parts:\n",
    "<ol>\n",
    "    <li>Input</li>\n",
    "    <li>prv_state</li>\n",
    "    <li>prv_output</li>\n",
    "    <li>new_state</li>\n",
    "    <li>new_output</li>\n",
    "</ol>\n",
    "\n",
    "<ul>\n",
    "    <li>Each LSTM cell has an input layer, which its size is 128 units in our case. The input vector's dimension also is 128, which is the dimensionality of embedding vector, so called, dimension size of Word2Vec embedding, for each character.</li>\n",
    "    <li>Each LSTM cell has a hidden layer, where there are some hidden units. The argument n_hidden=128 of BasicLSTMCell is the number of hidden units of the LSTM (inside A). It keeps the size of the output and state vector. It is also known as, rnn_size, num_units, num_hidden_units, and LSTM size, in literature.</li>\n",
    "    <li>An LSTM keeps two pieces of information as it propagates through time:</li> \n",
    "    <ul>\n",
    "         <li><b>hidden state</b> vector: Each LSTM cell accept a vector, called <b>hidden state</b> vector, of size n_hidden=128, and its value is returned to the LSTM cell in the next step. The <b>hidden state</b> vector; which is the memory of the LSTM, accumulates using its (forget, input, and output) gates through time. \"num_units\" is equivalant to \"size of RNN hidden state\". Number of hidden units is the dimensianality of the output (= dimesianality of the state) of the LSTM cell.</li>\n",
    "        <li><b>previous time-step output</b>: For each LSTM cell that we initialize, we need to supply a value (128 in this case) for the hidden dimension, or as some people like to call it, the number of units in the LSTM cell.</li> \n",
    "    </ul>\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "<h4>Stacked LSTM</h4>\n",
    "<p>What about if we want to have a RNN with stacked LSTM? For example, a 2-layer LSTM. In this case, the output of the first layer will become the input of the second.</p>\n",
    "\n",
    "num_layers = 2 \n",
    "<ul>\n",
    "    <li>number of layers in the RNN, is defined by <code>num_layers</code> parameter.</li>\n",
    "    <li>An input of MultiRNNCell is <b>cells</b> which is list of RNNCells that will be composed in this order.</li>\n",
    "</ul>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>3- Defining stacked RNN Cell</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<b>BasicRNNCell</b> is the most basic RNN cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to define a LSTM cell\n",
    "cell = tf.contrib.rnn.BasicRNNCell(rnn_size)\n",
    "# a two layer cell\n",
    "stacked_cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers)\n",
    "# hidden state size\n",
    "stacked_cell.output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<b>state</b> variable keeps output and new_state of the LSTM, so it is double in size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_cell.state_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets define the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(128, 50) dtype=int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])# a 128x50\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "and target data, what we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(128, 50) dtype=int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = tf.placeholder(tf.int32, [batch_size, seq_length]) # a 128x50\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The memory state of the network is initialized with a vector of zeros and gets updated after reading each character.\n",
    "\n",
    "<b>BasicRNNCell.zero_state(batch_size, dtype)</b> Return zero-filled state tensor(s). In this function, batch_size\n",
    "representing the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'MultiRNNCellZeroState/BasicRNNCellZeroState/zeros:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCellZeroState/BasicRNNCellZeroState_1/zeros:0' shape=(128, 128) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = stacked_cell.zero_state(batch_size, tf.float32) \n",
    "initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets check the value of the input_data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [39,  5,  3, ...,  0, 20,  9],\n",
       "       [ 0,  5,  9, ..., 19,  4, 13],\n",
       "       ...,\n",
       "       [ 3, 18, 18, ...,  1,  0, 23],\n",
       "       [ 7,  1, 23, ..., 18,  3,  7],\n",
       "       [47, 26, 24, ...,  0,  8,  3]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session(config=config)\n",
    "feed_dict={input_data:x, targets:y}\n",
    "session.run(input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>4- Embedding</h3>\n",
    "<p>In this section, we build a 128-dim vector for each character. As we have 60 batches, and 50 character in each sequence, it will generate a [60,50,128] matrix.</p>\n",
    "\n",
    "<p><b>Notice:</b> The function <code>tf.get_variable()</code> is used to share a variable and to initialize it in one place. <code>tf.get_variable()</code> is used to get or create a variable instead of a direct call to <code>tf.Variable</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnnlm', reuse=False):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65)\n",
    "    #with tf.device(\"/cpu:0\"):\n",
    "        \n",
    "    # embedding variable is initialized randomely\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "\n",
    "    # embedding_lookup goes to each row of input_data, and for each character in the row, finds the correspond vector in embedding\n",
    "    # it creates a 60*50*[1*128] matrix\n",
    "    # so, the first elemnt of em, is a matrix of 50x128, which each row of it is vector representing that character\n",
    "    em = tf.nn.embedding_lookup(embedding, input_data) # em is 60x50x[1*128]\n",
    "    # split: Splits a tensor into sub tensors.\n",
    "    # syntax:  tf.split(split_dim, num_split, value, name='split')\n",
    "    # it will split the 60x50x[1x128] matrix into 50 matrix of 60x[1*128]\n",
    "    inputs = tf.split(em, seq_length, 1)\n",
    "    # It will convert the list to 50 matrix of [60x128]\n",
    "    inputs = [tf.squeeze(input_, [1]) for input_ in inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets take a look at the <b>embedding</b>, <b>em</b>, and <b>inputs</b> variables:\n",
    "\n",
    "Embedding variable is initialized with random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00793244, -0.12151701,  0.0765961 , ..., -0.05543618,\n",
       "         0.13475265, -0.13977315],\n",
       "       [ 0.09853102, -0.17198418,  0.10010619, ..., -0.03239302,\n",
       "        -0.10837246,  0.06872773],\n",
       "       [-0.17029066, -0.1632553 ,  0.10661598, ..., -0.16106835,\n",
       "        -0.08031612,  0.02369289],\n",
       "       ...,\n",
       "       [ 0.02480979, -0.08533788,  0.04245146, ...,  0.04598148,\n",
       "         0.13664551,  0.00619262],\n",
       "       [-0.06675049,  0.10011525, -0.14581066, ...,  0.15248545,\n",
       "         0.09215359, -0.02051057],\n",
       "       [ 0.15475036, -0.01722795,  0.17334203, ..., -0.04756722,\n",
       "         0.11414908, -0.11109872]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "#print embedding.shape\n",
    "session.run(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The first elemnt of em, is a matrix of 50x128, which each row of it is vector representing that character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 50, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.06791009,  0.16086034, -0.09558129, ...,  0.13202943,\n",
       "         0.0621212 ,  0.05792509],\n",
       "       [ 0.07061861, -0.07791805,  0.08567737, ..., -0.03876969,\n",
       "         0.0141962 , -0.10702184],\n",
       "       [ 0.02997565, -0.16079615,  0.13437153, ..., -0.15121862,\n",
       "         0.02424981,  0.09875937],\n",
       "       ...,\n",
       "       [ 0.09853102, -0.17198418,  0.10010619, ..., -0.03239302,\n",
       "        -0.10837246,  0.06872773],\n",
       "       [ 0.04727341,  0.09932159, -0.07443327, ...,  0.00453392,\n",
       "        -0.03631479,  0.02924243],\n",
       "       [ 0.02997565, -0.16079615,  0.13437153, ..., -0.15121862,\n",
       "         0.02424981,  0.09875937]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = tf.nn.embedding_lookup(embedding, input_data)\n",
    "emp = session.run(em,feed_dict={input_data:x})\n",
    "print (emp.shape)\n",
    "emp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>Let's consider each sequence as a sentence of length 50 characters, then, the first item in <b>inputs</b> is a [60x128] vector which represents the first characters of 60 sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Squeeze:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_1:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_2:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_3:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_4:0' shape=(128, 128) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.split(em, seq_length, 1)\n",
    "inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "inputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>5- Feeding a batch of 50 sequence to a RNN:</h3>\n",
    "\n",
    "The feeding process for inputs is as following:\n",
    "<ul>\n",
    "    <li>Step 1: first character of each of the 50 sentences (in a batch) is entered in parallel.</li>  \n",
    "    <li>Step 2: second character of each of the 50 sentences is input in parallel.</li> \n",
    "    <li>Step n: nth character of each of the 50 sentences is input in parallel.</li>  \n",
    "</ul>\n",
    "<p>The parallelism is only for efficiency. Each character in a batch is handled in parallel, but the network sees one character of a sequence at a time and does the computations accordingly. All the computations involving the characters of all sequences in a batch at a given time step are done in parallel.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06791009,  0.16086034, -0.09558129, ...,  0.13202943,\n",
       "         0.0621212 ,  0.05792509],\n",
       "       [-0.04024461, -0.07659568,  0.05944164, ..., -0.07327118,\n",
       "         0.13993792,  0.05522346],\n",
       "       [-0.00793244, -0.12151701,  0.0765961 , ..., -0.05543618,\n",
       "         0.13475265, -0.13977315],\n",
       "       ...,\n",
       "       [ 0.09048764,  0.1603574 ,  0.11410554, ...,  0.0906067 ,\n",
       "        -0.01784791, -0.0499649 ],\n",
       "       [ 0.02997565, -0.16079615,  0.13437153, ..., -0.15121862,\n",
       "         0.02424981,  0.09875937],\n",
       "       [-0.12513085, -0.13164368,  0.12849973, ...,  0.09997953,\n",
       "        -0.09085518,  0.00936344]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(inputs[0],feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Feeding the RNN with one batch, we can check the new output and new state of network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_98:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_99:0' shape=(128, 128) dtype=float32>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs is 50x[60*128]\n",
    "outputs, new_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, initial_state, stacked_cell, loop_function=None, scope='rnnlm')\n",
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_1:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_3:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_5:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_7:0' shape=(128, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_9:0' shape=(128, 128) dtype=float32>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's check the output of network after feeding it with first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00451643,  0.12399019, -0.07594457, ..., -0.05181948,\n",
       "        -0.14754444,  0.02062858],\n",
       "       [-0.00111185,  0.05127876,  0.00685722, ...,  0.00121019,\n",
       "        -0.06473307,  0.07412098],\n",
       "       [ 0.03569369, -0.01327778,  0.02757602, ..., -0.04663751,\n",
       "        -0.13133056, -0.09651423],\n",
       "       ...,\n",
       "       [ 0.09379835,  0.02671058, -0.12557708, ..., -0.04537715,\n",
       "         0.06903224,  0.01858358],\n",
       "       [ 0.04514822, -0.01260123,  0.08135197, ...,  0.09812014,\n",
       "        -0.01556917,  0.05337349],\n",
       "       [ 0.07625125, -0.06457734,  0.04341412, ..., -0.00206237,\n",
       "         0.0751951 , -0.03273529]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_output = outputs[0]\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(first_output,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>As it was explained, <b>outputs</b> variable is a 50x[60x128] tensor. We need to reshape it back to [60x50x128] to be able to calculate the probablity of the next character using the softmax. The <b>softmax_w</b> shape is [rnn_size, vocab_size], which is [128x65] in our case. Therefore, we have a fully connected layer on top of LSTM cells, which help us to decode the next charachter. We can use the <b>softmax(output * softmax_w + softmax_b)</b> for this purpose. The shape of the matrixis would be:</p>\n",
    "\n",
    "softmax([60x50x128]x[128x65]+[1x65]) = [60x50x65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We can do it step-by-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(6400, 128) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(tf.concat( outputs,1), [-1, rnn_size])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(6400, 65) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(6400, 65) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = tf.nn.softmax(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here is the probablity of the next chracter in all batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01243575, 0.01640613, 0.01337954, ..., 0.01421831, 0.01235159,\n",
       "        0.01496653],\n",
       "       [0.0186899 , 0.01789637, 0.01097039, ..., 0.01259695, 0.01566873,\n",
       "        0.0122199 ],\n",
       "       [0.0130527 , 0.01496357, 0.01174692, ..., 0.01285152, 0.01314129,\n",
       "        0.01767668],\n",
       "       ...,\n",
       "       [0.01920776, 0.0178632 , 0.01119502, ..., 0.01427422, 0.01136752,\n",
       "        0.00993043],\n",
       "       [0.01488299, 0.01668921, 0.01141684, ..., 0.01416054, 0.00861541,\n",
       "        0.01281932],\n",
       "       [0.01229749, 0.02165352, 0.01410553, ..., 0.01664305, 0.01394596,\n",
       "        0.01565781]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(probs,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, we are in the position to calculate the cost of training with <b>loss function</b>, and keep feeding the network to learn it. But, the question is: what does the LSTM networks learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnnlm/softmax_w:0' shape=(128, 65) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/softmax_b:0' shape=(65,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/embedding:0' shape=(65, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clip =5.\n",
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Okay, by now, you should understand enough about each component of a LSTM network to be able to train it, and predict the next word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>All together</h2>\n",
    "Now, let's put all of parts together in a class, and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel():\n",
    "    def __init__(self,sample=False, device='/cpu:0'):\n",
    "        rnn_size = 128 # size of RNN hidden state vector\n",
    "        batch_size = 128 # minibatch size, i.e. size of dataset in each epoch\n",
    "        seq_length = 50 # RNN sequence length\n",
    "        num_layers = 2 # number of layers in the RNN\n",
    "        vocab_size = 65\n",
    "        grad_clip = 5.\n",
    "        if sample:\n",
    "            batch_size = 1\n",
    "            seq_length = 1\n",
    "        with tf.device(device):\n",
    "            # The core of the model consists of an LSTM cell that processes one char at a time and computes probabilities of the possible continuations of the char. \n",
    "            basic_cell = tf.contrib.rnn.BasicRNNCell(rnn_size)\n",
    "            # model.cell.state_size is (128, 128)\n",
    "            self.stacked_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * num_layers)\n",
    "\n",
    "            self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length], name=\"input_data\")\n",
    "            self.targets = tf.placeholder(tf.int32, [batch_size, seq_length], name=\"targets\")\n",
    "            # Initial state of the LSTM memory.\n",
    "            # The memory state of the network is initialized with a vector of zeros and gets updated after reading each char. \n",
    "            self.initial_state = stacked_cell.zero_state(batch_size, tf.float32) #why batch_size\n",
    "\n",
    "            with tf.variable_scope('rnnlm_class1'):\n",
    "                softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "                softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "                inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), seq_length, 1)\n",
    "                inputs = [tf.squeeze(input_, [1]) for input_ in inputs] \n",
    "\n",
    "            # The value of state is updated after processing each batch of chars.\n",
    "            outputs, last_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, self.initial_state, self.stacked_cell, loop_function=None, scope='rnnlm_class1')\n",
    "            output = tf.reshape(tf.concat(outputs,1), [-1, rnn_size])\n",
    "            self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "            self.probs = tf.nn.softmax(self.logits)\n",
    "            loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                    [tf.reshape(self.targets, [-1])],\n",
    "                    [tf.ones([batch_size * seq_length])],\n",
    "                    vocab_size)\n",
    "            self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "            self.final_state = last_state\n",
    "            self.lr = tf.Variable(0.0, trainable=False)\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),grad_clip)\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "            self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    \n",
    "    def sample(self, sess, chars, vocab, num=200, prime='The ', sampling_type=1):\n",
    "        state = sess.run(self.stacked_cell.zero_state(1, tf.float32))\n",
    "        #print state\n",
    "        for char in prime[:-1]:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = prime\n",
    "        char = prime[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = probs[0]\n",
    "\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if char == ' ':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else: # sampling_type == 1 default:\n",
    "                sample = weighted_pick(p)\n",
    "\n",
    "            pred = chars[sample]\n",
    "            ret += pred\n",
    "            char = pred\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"cpu_vs_gpu\"></a>\n",
    "<h2>Train your model using CPU and GPU</h2>\n",
    "We can train our model through feeding batches. You should be able to complete the following cells and submit it for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_1\"></a>\n",
    "<h2>Question 1: Complete the code to run it on CPU</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/3480 (epoch 0), train_loss = None, time/batch = 0.05638575553894043\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The mest ax time re to mesvy grou theald your wlloneeds, sengir ag to-d tre hes the wrone!\n",
      "\n",
      "F I kive heat' woll wete nucemant buth mandens; anle:\n",
      "Ne now t\n",
      "----------------------------------\n",
      "347/3480 (epoch 1), train_loss = None, time/batch = 0.05362653732299805\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The a my wet the wety comas.\n",
      "Sor do rey is liwill bo mas\n",
      "To be that be alver if sy mroncees the\n",
      "pricisofdup in should have Juctycom'ss Omhear!\n",
      "\n",
      "Sirf Etre \n",
      "----------------------------------\n",
      "521/3480 (epoch 2), train_loss = None, time/batch = 0.055547475814819336\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The such do his nir peass for ow your to know of me strone. My whink by to shely, of hen, the fatmy\n",
      "Benit,\n",
      "We fear the pops, and seir\n",
      "For a hone, I daurk,\n",
      "----------------------------------\n",
      "695/3480 (epoch 3), train_loss = None, time/batch = 0.057756662368774414\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The sive thunged than my a fassterny feer?\n",
      "'Tis, It ponuth?\n",
      "\n",
      "LUCI HESS HESS MENRUME Lors for the proplien Jurneptiouse?\n",
      "\n",
      "TtARUNII:\n",
      "And stre sunt I nobluni\n",
      "----------------------------------\n",
      "869/3480 (epoch 4), train_loss = None, time/batch = 0.05832076072692871\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The such owarr'd verabed, in the earn; and he worns\n",
      "At ithrolalte arsal:\n",
      "Bring this like the know my sovan ans thescerelly\n",
      "Time you can hear;\n",
      "And thone bi\n",
      "----------------------------------\n",
      "1043/3480 (epoch 5), train_loss = None, time/batch = 0.05325818061828613\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Citizen:\n",
      "wandsty their heack on your suppace, and it say--\n",
      "\n",
      "SArapour, stowy trut no me my stost\n",
      "Caster wird strect he roolecias flarger it supperitura\n",
      "----------------------------------\n",
      "1217/3480 (epoch 6), train_loss = None, time/batch = 0.0582582950592041\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The fied vors strun. How this earged leh to the were his breather in a poift;\n",
      "Go; dee he our in ifter chail?\n",
      "U'll begined the day the Genind, we but ring \n",
      "----------------------------------\n",
      "1391/3480 (epoch 7), train_loss = None, time/batch = 0.05662894248962402\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Wilt bedibed trues Landyriaf to be go lodder\n",
      "As well be claramy\n",
      "Were then\n",
      "I'thing stors' hir.\n",
      "\n",
      "LARIOLI:\n",
      "Has my fatiory,\n",
      "Coms their of it.\n",
      "\n",
      "DUCHESS OF \n",
      "----------------------------------\n",
      "1565/3480 (epoch 8), train_loss = None, time/batch = 0.06055307388305664\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The sour furself; crown thy bust rehom thus\n",
      "That wome ill hid from siltent, that depornece,\n",
      "My loants,\n",
      "You the from my mine dame!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I lady \n",
      "----------------------------------\n",
      "1739/3480 (epoch 9), train_loss = None, time/batch = 0.05375504493713379\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The spery or the a valusaber.'\n",
      "\n",
      "AUTIA:\n",
      "For agars, as 'tis wast twert your cup in my?\n",
      "\n",
      "FRIAS:\n",
      "My whill the llears,\n",
      "That none, letten when was a piretain, a\n",
      "----------------------------------\n",
      "1913/3480 (epoch 10), train_loss = None, time/batch = 0.061136484146118164\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The world.\n",
      "\n",
      "TRANIO:\n",
      "He noe youth\n",
      "A writous of propless too much;\n",
      "Whils to soverest bloher!\n",
      "We show, but cold.\n",
      "Candininition,\n",
      "When perford, anger your powe\n",
      "----------------------------------\n",
      "2087/3480 (epoch 11), train_loss = None, time/batch = 0.057736873626708984\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The oftenish'd in his foul land; the mold,\n",
      "To much tuse I had lesch\n",
      "he shalue, none.' Bead, when you or\n",
      "Which will ment unjust seemed and violeft Aneise t\n",
      "----------------------------------\n",
      "2261/3480 (epoch 12), train_loss = None, time/batch = 0.057866573333740234\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The on theich we not to perfold in brother:\n",
      "She hath his down will honours\n",
      "Known wis more,\n",
      "A very break\n",
      "Thus eithalds doth\n",
      "Suce that in fellow'd life,\n",
      "And\n",
      "----------------------------------\n",
      "2435/3480 (epoch 13), train_loss = None, time/batch = 0.050054311752319336\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The whore, I will to my graviship?-\n",
      "As, into's you; I deward, to may sent mean, succed on eld a heart to me vaniar to the manfast: say, said with mataim.\n",
      "\n",
      "----------------------------------\n",
      "2609/3480 (epoch 14), train_loss = None, time/batch = 0.051917314529418945\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The ragains my tongue stone. How do the sun suhe of thy dowful pard! what's offom offechabe and my till the breath\n",
      "Ay, and for the flams the nuct to power\n",
      "----------------------------------\n",
      "2783/3480 (epoch 15), train_loss = None, time/batch = 0.05416083335876465\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The king, whire's the reabm of a king as straisce. Threet thee-voicel:\n",
      "My crown sanger for all with me:\n",
      "Well, will begn that fear,\n",
      "As if out strone:\n",
      "I dow\n",
      "----------------------------------\n",
      "2957/3480 (epoch 16), train_loss = None, time/batch = 0.05163407325744629\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The his deak to me.\n",
      "\n",
      "Baich, still not?\n",
      "\n",
      "Servant:\n",
      "My latter for Gaunch the very secilaw, my liff that hath true my\n",
      "powards,\n",
      "And notting ungenane forson:\n",
      "Pe\n",
      "----------------------------------\n",
      "3131/3480 (epoch 17), train_loss = None, time/batch = 0.053758859634399414\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The begee ever in warm,\n",
      "Glore thy corns? come, prince, Tureshigness life,\n",
      "You toward, and Henry have it maple his\n",
      "not frocken in my true Rome amina\n",
      "I that\n",
      "----------------------------------\n",
      "3305/3480 (epoch 18), train_loss = None, time/batch = 0.052324533462524414\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The foim,\n",
      "My lawfuvings;\n",
      "To be maught the king lies my deals him; I have did be prry\n",
      "Blamk peis very grood body beace,\n",
      "And such showl to him back.\n",
      "But I a\n",
      "----------------------------------\n",
      "3479/3480 (epoch 19), train_loss = None, time/batch = 0.05606698989868164\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The remphereinne-The sit: pranged inter lies ah you.\n",
      "\n",
      "Gentle:\n",
      "I ligh?\n",
      "\n",
      "AUTISSA:\n",
      "Fast to sher, that, was murtors:\n",
      "Undure boy; for forth, a garget, yet conf\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "avg_batch_running_duration_CPU=[]\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"rnn_CPU\"):\n",
    "    model = LSTMModel(device='/cpu:0')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 20 for test, but should be higher\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        ## write your code bellow to reset the batch pointer in data_loader. you can use reset_batch_pointer()\n",
    "        data_loader.reset_batch_pointer()\n",
    "        \n",
    "        state = sess.run(model.initial_state) # model initialization\n",
    "        batch_running_duration_CPU = []\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            ## write your code to define your x and y. You should use next_batch() from data_loader\n",
    "            ## e.g. x,y = \n",
    "            \n",
    "            x,y = data_loader.next_batch()\n",
    "            \n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}\n",
    "            \n",
    "            ## write your code to train the model\n",
    "            ## fe.g.: train_loss, state, _ = \n",
    "            train_loss, state, _ = sess.run([model.train_op, model.final_state,model.probs], feed_dict= feed)\n",
    "\n",
    "            end = time.time()\n",
    "            \n",
    "            ## write your code to store the duration of runing each batch in a list (end - start)\n",
    "            batch_running_duration_CPU.append(end - start)\n",
    "            \n",
    "        print(\"{}/{} (epoch {}), train_loss = {}, time/batch = {}\".\\\n",
    "              format(e * data_loader.num_batches + b, num_epochs * data_loader.num_batches, e, train_loss, end - start))\n",
    "        \n",
    "        avg_batch_running_duration_CPU.append(sum(batch_running_duration_CPU) / float(len(batch_running_duration_CPU)))\n",
    "        \n",
    "        # Please uncomment the following block of the code so the grader can see the sample of prediction\n",
    "        with tf.variable_scope(\"rnn_CPU\", reuse=True):\n",
    "            sample_model = LSTMModel(sample=True)\n",
    "            print ('----------------------------------')\n",
    "            print ('SAMPLE GENERATED TEXT:')\n",
    "            print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=150, prime='The ', sampling_type=1))\n",
    "            print ('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_2\"></a>\n",
    "<h2>Question 2: Complete the code to run it on GPU</h2>\n",
    "Now, create the same network with GPU, and calculate the time/batch for running each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/3480 (epoch 0), train_loss = None, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The mas. tha ba houch thcateler this marde, Qrey, Horingedes. mend cale It this t'an sued sow bftry aror''s plise his ofpreghan--fouth you plerint she kee\n",
      "----------------------------------\n",
      "347/3480 (epoch 1), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The heae me, the kid, and spuakbred he may shere-uncule, but in' bey senell.\n",
      "\n",
      "PROMENE:\n",
      "On nors for I was but my ip,\n",
      "-pearn wollud the bit.\n",
      "\n",
      "COMINES:\n",
      "Whre \n",
      "----------------------------------\n",
      "521/3480 (epoch 2), train_loss = None, time/batch = 0.021\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The drake of them, lovesicost itworming: he whing, and flow under in his by makes fathing.\n",
      "\n",
      "FirlUmbcanter upie were tare on in us yes martor:\n",
      "That erine o\n",
      "----------------------------------\n",
      "695/3480 (epoch 3), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The worknous\n",
      "are loveriant, will me earth,\n",
      "And you now and tid ands, whou stams, a tranceman:\n",
      "\n",
      "CLORENCO:\n",
      "NQUnks, to ast for the vane\n",
      "Tho have sines,\n",
      "Ponou\n",
      "----------------------------------\n",
      "869/3480 (epoch 4), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The gried, then owas beast chander:\n",
      "Hasth in, let he will you ge''t to be't with is good. Lord I lall of ayay:\n",
      "Some his rebern shaps,\n",
      "Dijen whath is my ol\n",
      "----------------------------------\n",
      "1043/3480 (epoch 5), train_loss = None, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The farthing dike\n",
      "For may, this the kindref that to Pefeid.\n",
      "\n",
      "PETEN:\n",
      "Meny,\n",
      "And is must on the treat evorn. Gaviin;' thus of is wold cason on the is read.\n",
      "T\n",
      "----------------------------------\n",
      "1217/3480 (epoch 6), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The queen and fean nease our ben\n",
      "Untwerels thy partfes andeat,\n",
      "And drivor shall speecit dies feat yout!\n",
      "Goese I she me, he will but disposes voings no kin\n",
      "----------------------------------\n",
      "1391/3480 (epoch 7), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The power visite, that may we'll new the crown of yearn.\n",
      "\n",
      "DUKE OF EDs?\n",
      "\n",
      "FLORIZELO:\n",
      "I\n",
      "I think the vely wity by with whop to my cold, and a rights;\n",
      "For stay\n",
      "----------------------------------\n",
      "1565/3480 (epoch 8), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The gobsalf, oft this brothard know: what which thinking, all e lose.\n",
      "\n",
      "First Masced, lord?\n",
      "\n",
      "COMINIUS:\n",
      "Basqueen me with their toot ither, Inhep's mishy hea\n",
      "----------------------------------\n",
      "1739/3480 (epoch 9), train_loss = None, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The know his face,\n",
      "Told on my soul ttick the given, my doaking of hund ficced, take thee day: say,\n",
      "For thou hope witbout. Come:\n",
      "Lerce as loy.\n",
      "\n",
      "DULUET:\n",
      "A d\n",
      "----------------------------------\n",
      "1913/3480 (epoch 10), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The siding to-please to.\n",
      "\n",
      "First'B Purking great on!\n",
      "To the dury we will plyie than says vind for this pererary, words\n",
      "A shalf your graca?\n",
      "There up; lais; \n",
      "----------------------------------\n",
      "2087/3480 (epoch 11), train_loss = None, time/batch = 0.021\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The meds:\n",
      "What tend thou days is woe this earth, stay's brows and.\n",
      "\n",
      "GRECHASTER:\n",
      "Shall with you take this gentlemf.\n",
      "\n",
      "KING EDWARD IV:\n",
      "That which?'\n",
      "'Shall ra\n",
      "----------------------------------\n",
      "2261/3480 (epoch 12), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Prjudge! Prough the councale with not\n",
      "Op this bhore:\n",
      "Of ulack.\n",
      "Is bluss,\n",
      "Busage married, arrant againt,\n",
      "I cull him cIs sugenard's couse sightren conve\n",
      "----------------------------------\n",
      "2435/3480 (epoch 13), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The overed oliness affecting,\n",
      "That will well to us\n",
      "Besop-time thy enish the weatin somed deatens that I be eronginess, I farlign, fas' known you bitys and\n",
      "----------------------------------\n",
      "2609/3480 (epoch 14), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The me in't.\n",
      "Will not brows the fuwM titte this paoty shiling attends is let even?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Your enath'd\n",
      "A city of the gentlemen!\n",
      "\n",
      "WARWICK:\n",
      "O love\n",
      "----------------------------------\n",
      "2783/3480 (epoch 15), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The Guese; if if\n",
      "That sheet the iance to-cet hove boly you need costants wilt my lawer, that I cannod the poor shall reaund care,\n",
      "Whilt Rostest impless is\n",
      "----------------------------------\n",
      "2957/3480 (epoch 16), train_loss = None, time/batch = 0.022\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The know lift them spop'd she good wratch; whos profome then you see, sithal, with his merchiver\n",
      "He'll ungres.\n",
      "\n",
      "DUCHESS OF YOND LUTE:\n",
      "My gupster:\n",
      "Thy entr\n",
      "----------------------------------\n",
      "3131/3480 (epoch 17), train_loss = None, time/batch = 0.020\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The embald\n",
      "that lieged Sin.\n",
      "With credinate\n",
      "And look; is metimety, by blood\n",
      "A birn shall swies of mistrusunes--to hush husband,--nifsed for the leaving Ric\n",
      "----------------------------------\n",
      "3305/3480 (epoch 18), train_loss = None, time/batch = 0.019\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The be\n",
      "Tybalt,\n",
      "I proarly me then, petchman is goide.\n",
      "\n",
      "Second Servingman:\n",
      "Take the mour tears; thy hither.\n",
      "\n",
      "COMINIUS:\n",
      "But their kisson--it posse of feeding\n",
      "----------------------------------\n",
      "3479/3480 (epoch 19), train_loss = None, time/batch = 0.024\n",
      "----------------------------------\n",
      "SAMPLE GENERATED TEXT:\n",
      "The There:\n",
      "Could such a boy, let with side. That is't a measure these stead, lie: my enemiling in the made it power it. Brow the great\n",
      "By Bianca\n",
      "Jount tha\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Create the same network using GPU\n",
    "\n",
    "\n",
    "avg_batch_running_duration_GPU=[]\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"rnn_GPU\"):\n",
    "    model = LSTMModel(device='/gpu:0')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 20 for test, but should be higher\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        ## write your code bellow to reset the batch pointer in data_loader. you can use reset_batch_pointer()\n",
    "        data_loader.reset_batch_pointer()\n",
    "\n",
    "        \n",
    "        state = sess.run(model.initial_state) # model initialization\n",
    "        batch_running_duration_GPU = []\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            ## write your code to define your x and y. You should use next_batch() from data_loader\n",
    "            ## e.g. x,y =\n",
    "            x,y = data_loader.next_batch()\n",
    "\n",
    "            \n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}            \n",
    "            ## write your code to train the model\n",
    "            ## fe.g.: train_loss, state, _ = \n",
    "            train_loss, state, _ = sess.run([model.train_op, model.final_state,model.probs], feed_dict= feed)\n",
    "\n",
    "            \n",
    "            end = time.time()\n",
    "            ## write your code to store the duration of runing each batch in a list (end - start)\n",
    "            ##\n",
    "            batch_running_duration_GPU.append(end - start)\n",
    "\n",
    "            \n",
    "        print(\"{}/{} (epoch {}), train_loss = {}, time/batch = {:.3f}\" \\\n",
    "                .format(e * data_loader.num_batches + b, num_epochs * data_loader.num_batches, e, train_loss, end - start))\n",
    "        avg_batch_running_duration_GPU.append(sum(batch_running_duration_GPU) / float(len(batch_running_duration_GPU)))\n",
    "        \n",
    "        # Please uncomment the following block of the code so the grader can see the sample of prediction\n",
    "        with tf.variable_scope(\"rnn_GPU\", reuse=True):\n",
    "            sample_model = LSTMModel(sample=True)\n",
    "            print ('----------------------------------')\n",
    "            print ('SAMPLE GENERATED TEXT:')\n",
    "            print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=150, prime='The ', sampling_type=1))\n",
    "            print ('----------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"question_3\"></a>\n",
    "<h2>Question 3: Compare the results</h2>\n",
    "Finally, using a graph, show the speed of training (batch/time) for the model running on GPU and CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Epochs vs Average batch running duration time in GPU')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4HNW5uN9PXbbcLVmSZcm9SS6SZbADsklIMASwCTbFDgkl5ZKEQMr9JeEmIYRwk5ubAqmXCykkMWCaHGzKJXRMkcDG3XIvWM3dlmSr6/v9MbNivd5djaSd3ZV03ueZZ3dnzpzz7e7sfHu+dkRVMRgMBoMh1MREWgCDwWAw9E6MgjEYDAaDKxgFYzAYDAZXMArGYDAYDK5gFIzBYDAYXMEoGIPBYDC4glEwEUREVETGR1qO3oyIPCwi94ZhnItEpNztcbqKiGwVkYvCMM5o+7qOc3ssrzHD8t7ssepEZGwYxnlARH7o9jhuYxSMjYjsF5F6+wLybL+PtFzhxr4ht4hIZqRliTQicreILI+0HKFAVXNV9fVIy9Fd/P1hcOu9icjrIvJFn7FSVHVvqMfyRVVvVdWfdPV8EVkgIm+KSK2IHBGRN0RkoX3sJhFpte9xNSKyQUSu8Dr2lp/+9ovIJzsrh1EwZ3OlfQF5ttsiLVA4EZH+wGLgFPBZl8YI2z/bnoJY9Pnfork2QoOILAGeBP4OZAEjgLuAK72avauqKcBg4M/AEyIyNOTCqKrZrGoG+4FPBjh2E/A28Dusm+924GKv45nAKuA4sBv4ktexWOA/gD1ALbAOGGUfU+BWYBdwAvgDIPax8cAb9nhHgccDyPZ/wG0++zYCVwMC3AcctvvZBOQF+Qw+DxwE7gC2+Ly/emCo1758W654+/UtQJn9Pl4EcrzaKvA1+33us/f9xh6rxv5MirzaJwN/s/sqA74DlPvI8zRwBNgH3B7kPT0MPAC8ZH/+b/jI5lcO4FKgCWgG6oCN9v6hwF+BSlu+f9r7LwLKgW/bn3cVcHMQuV4H/tO+rurt73s/XtcgcDew3H4+2v4cbwQ+tD/77/u0fQLrplILbAUK/V3fDtoWAOvtY08CjwP3BngfscAvbXn22t+zAnH+flcB3tMX7Pf0pr3/SaAa65p9E8i193/Z/j6a7O9ktZ/3lgjcb38/lfbzxM5+R/Z30wo02GP93utaHu91bf0ReMFu8zaQbo95Aus+kd+N6/beLsgt9mf5/4L0fRPwltfr/vb7KvQ95uT+GPS+2tkTeusW7AO0P/QW4JtAPHCdffEPtY+/YV9oScBM+wK62D72/4DNwCT7y58BDPO6WJ/F+heRbZ93qX3sMeD7WLPMJODCALJ9Hnjb6/VU4KT9Q1uAddMcbI89BcgI8hm8Avw31j+eFqDA69irnK04fwE8YD+/CkuxTgHigB8A73i1Vawb/FAg2d53AzDMbv9trBtKkn3sv+zPdAjWP7BN2ArG/jzWYf0jSwDGYt3YFgR4Tw9j3Sjn2Z/Jb3x+XMHkuBv7ZujV/jmsG+4Q+1qYb++/yP7M7rH3fxo4AwwJINfrWDeCXHvseJzdjB/CUsAzgEZgilfbBnvcWOBnQIm/6ztYW/szPYD1JyMe649KE4EVzK1YN9JR9vf7Gp1XMH/Husl5ro1bgAF8pCw2+Hyf9/rI4P3e7gFKgDQgFXgH+Ek3vqMv+uzzVTBHgVlYv9FXsRTH5+3P9V7gtW5ct/d2Vm5gsi3jmCC/85uwfwNY194dWL+RQRgF485mf4B1WDdnz/Ylry+kEnt2Ye97D/ic/cNqBQZ4HfsZ8LD9fAewKMCYipfiwPpX+T37+d+BB4GsDuQeAJzG/leO9c/rL/bzTwA7gTlATAf9ZANtwEz79YvAb7yOfxF41X4uWP/659mvXwC+4NU2xv4B5Hi9z090MP4JYIb9/Kwfnj22R8GcD3zoc+6dwF8D9PswsMLrdYr9fY1yIMfdeCkYIMP+jPz9sC/CmonEee07DMwJMM7rwD1+rsGObsZZXsffA673avuy17GpQL2/voO1xVLEFZx9rb9FYAXzKnCr1+tL6LyCGRvkuhhstxnk9X0GUzB7gE97HVsA7O/Gd9SRgnnI69jXgTKv19OAk924bu/trNzABbaMSUE+05uwFNZJLAVZ4vX53UQIFUyft/v6cJWqDvbaHvI6VqH2J21zAGvKmwkcV9Van2Mj7eejsC76QFR7PT+DdQMEyywkwHt2lMwt/k62x30OuN7edT3wiH3sVeD3WKa3QyLyoIgMDCDH57B+HBvs148Ay0Qk3n79FDDXdv7Pw7qI19jHcoDfiMhJETmJZSoUr88ALIXUjoh8W0TKROSUfc4gYLh9ONOnvffzHCDTM5Z97n9gzboC0X6+qtbZ8mU6kMOXUVjf9YkAx4+paovXa+/vM6hcnSDQ9eLvWFIQv0agtpmce60Hk9P3uzoQpG0g2s8XkVgR+S8R2SMiNVg3Ngj8nfiTx1sGz+/UQ2e/o4445PW83s9rT99duW69cSr3Mfsxo4P+Sux73HBVnaOqL9v7W7BmSb7EY5knO4VRMM4ZKSLi9Tqbj+y8Q0VkgM+xCvv5QWBcZwdT1WpV/ZKqZgL/BvwxSEjzY8BSEZmLZT55zauf36rqLCxTzEQsk50/Pg+MFZFqEakGfo31o77M7uck8C/gWmAZ8JjXTegg8G8+yjlZVd/xfkueJyJSBHzX7muIqg7GMjl6Pt8qLNOYh1Fezw9i+XG8xxqgqp8O8L7OOl9EUrBMOZUO5FCffg5ifdeDg4zVGXz7Pw3083qdHqJxOkMV517rowI1ttt7H8/2Oe7kPXl/DsuARcAnsZT9aHt/oO/El0qsm7m3PJUdnBOIjsbqDF25brvCDnusxV08/0Mg2/v7F5F+WCbHTv95MArGOWnA7SISLyLXYPkbnlfVg1h23p+JSJKITMdyWj5in/cn4CciMsGOFpouIsM6GkxErhERz032BNbF3hqg+fNYP6p7sIIB2uw+ZovI+fYs5DSW3f2cPmzFNA44D8uHNBPIAx7Fcip7eBRLES22n3t4ALhTRHLt/gbZn1EgBmD9UzoCxInIXYD3zOoJu78hIjIS8I7mew+oEZHvikiy/Y83T0RmBxnv0yJyoYgkAD8BSu3vrSM5DgGjPRFeqlqFZQ78oy1bvIjMCzJuZ9kAXG/3WwgsCWHfTnkX6xq5TUTiRGQR1nURiCewfhdZIjIE+J7P8c6+pwFYvqVjWIrppz7HD2H5LwLxGPADEUkVkeFYPo+uhpp3NFZn6Mp122nsP33fAn4oIjeLyEARibGv/wcddFGKdZ/4nn0/64/lE12LUTDdZrWcnQez0utYKTABy2b5n8ASVfVMR5di/dOqBFYCP1LVl+xjv8b6Ef4LK1Lpz1izjI6YDZSKSB1WhNodqrrPX0NVbQSKsf71ed/4B2I5hU9gXRzHsCJ+fLkReEZVN9szp2pVrcZyiF/hFb64yv4MDqnqRq/xVwI/B1bYZo0t2DOfALyIdaPeacvVwNlmlnuwomb2AS9jmeca7bFascItZ9rHj2Ip8UFBxnsU+BGWaWwWH4VgdyTHk/bjMRH5wH7+OSxTwXYsO/g3gozbWX6IpehPAD/m7O8yLKhqE5Zj/wtYNvobsAJRGgOc8hDW57gR+ADrOvSms+/p71jfRQWwDcs/4M2fgam2memffs6/F+tmuAkruOYDe19X+A2wREROiMhvu9gH0OXrtqtjPYUViHQL1j3pENZn8IyDcxuBy/kocm0vlonxWh+zqSOkC+f0OUTkJixn34WRlqUvIiJfwXJmz4+0LH0RESnFihj8a6RlMfQszAzGEHWISIaIXGBP7SdhhQ+v7Og8Q2gQkfkikm6byG4EpmPlWxkMncJkzhqikQTgf4ExWGaaFVh5RobwMAnLrJuCFQG5xPY/GQydwpjIDAaDweAKxkRmMBgMBlfo0yay4cOH6+jRoyMthsFgMPQo1q1bd1RVUztqF1DBiMjvODvRSLFC615T1XPKOfdERo8ezdq1ayMthsFgMPQoRMRRTkywGYy/O+9Q4Bci8riq3t8lyQwGg8HQJwioYFT1b/72i8gDWJnrHSoYEbkUK1kpFviTqv6Xz/FErMSqWVhJgNep6n4RGY1Vpn2H3bREVW+1y7Gs8eoiC6tw3jcC9dWRjAaDwWBwh077YFS1/uwyRf4RkVisIoufwsoIfV9EVqnqNq9mXwBOqOp4EbkeKxv8OvvYHlWd6TN2LVYmrGeMdXyUORysL4PBYDCEmU5FkdmJVzdjKYyOOA/Yrap77fITK7CK2HmzCGthKbDKgVwsTrSXJcsErPpgnhlNl/syGAwGQ+gJqGDEWsu5xn6stWtMVWDVmPo3B32P5Oy6TuWcXb79rDZ2KepTWIs/AYwRkfVirSVd5Kf/pViFHT2BCMH68n5fXxaRtSKy9siRIw7ehsFgMBi6QjAfzIBAxxzib/bgm9UZqE0VkK2qx0RkFvBPEclV1RqvdtdjFR7szHio6oNYC3lRWFhoskwNBoPBJYLNYNJE5H4ReVZEfiqBF6oKRDlnrxORxbnrMrS3EWuxo0FYCzo1eioVq+o6rHIVE71km4G1utu6jvrqpMwGg8FgCBHBfDB/x1pD5HdYazR0tlz1+8AEERljr8NxPVa5d29W8dF6I0uwluRVey2HWAARGYtVIn6v13lLsdZ96LCvTspsMBhcprWtlT998CcaWhoiLYrBZYJFkaWr6vft5y96rYfhCFVtEZHbsNaKiMVaJ36riNwDrFXVVVhrO/xDRHZjzTY8y/7OA+4RkRasxY9uVVXv2ci1gO9KcIH6MhgMUURJeQlfWv0lWtpauLXw1kiLY3CRYApG7BXqPL6NWO/XPjd8v6jq81irLXrvu8vreQNwzsqHqvo08HSQfs9ZZS5QXwaDIboor7GCUFfvXG0UTC8nmIIZBKzjbOe5ZxajhG4pUYPB0IeoqrMq/7+y9xXqmupISUiJsEQGtwgWRTY6jHIYDIY+QmWtFevT2NrIv/b8i6unXB1hiQxuESyKbIGILPGzf5mIfMpdsQwGQ2+lqq6KrIFZDEkawqodvnE/ht5EMBPZj4Er/ex/FWv52pdckchgMPRqKmsrGTVwFOOGjuPZnc/S2tZKbExspMUyuECwMOV+qnpOqruqVgP93RPJYDD0Zqpqq8gckMnCiQs5Vn+Mdw6+E2mRDC4RTMEk2QmLZyEi8UCyeyIZDIbeTFVdFRkpGSwYv4D4mHhjJuvFBFMwxcBDItI+W7GfP8BHFYwNBoPBMfXN9ZxsOEnmgEwGJg7kE2M+waqdRsH0VoIpmB8Ah4ADIrLOLo2/HzhiHzMYDIZO4QlRzhiQAcDCSQvZeWwn249uj6RYBpcIqGBUtUVVv4dV3+sme8tW1e+panN4xDMYDL0JT4hy5oBMAK6caMURGTNZ76TD9WBUtV5VN9tbfTiEMhgMvZOqWnsGk2LNYEYNGkVBRoFRML2UTi04ZjAYDN3BdwYDsHDiQt45+A5HTpv1mXobRsEYDIawUVVXRUJsAkOTh7bvWzhpIYry7M5nIyiZwQ0cKRgRGSkiHxOReZ7NbcEMBkPvo7K2koyUDLxXM5+ZPpNRA0eZaLJeSLBMfgBE5OfAdcA2rNL5YBW7fNNFuQwGQy+kqq6qPYLMg4iwcNJC/rrhr9Q315Mcb9LsegtOZjBXAZNU9dOqeqW9LXRbMIPB0PvwzGB8WThpIWeaz/DKvlciIJXBLZwomL1AvNuCGAyG3o+nTIwv83PmMyBhgIkm62V0aCIDzgAbROQVoNGzU1Vvd00qg8HQ62hoaeBEwwm/M5jEuEQum3AZq3eupk3biBETf9QbcPItrgJ+AryDtQCZZzMYDAbHeHJg/M1gwApXrq6r5v2K98MplsFFOpzBqOrfwiGIwWDo3fiWifHlsgmXESuxrNqxivOzzg+naAaXCLbg2BP242YR2eS7hU9Eg8HQG/CXZOnN0OShzMuZZ8KVexHBZjB32I9XhEMQg8HQu/EtE+OPhZMW8s0Xv8neE3sZO2RsuEQzuESwYpdV9uMBf1v4RDQYDL2BytpK4mPiGdZvWMA2pvhl78KEahgMhrBQVVdFekp60AixcUPHkZuaaxRML8EoGIPBEBYqaysD+l+8WTRpEW8eeJMT9SfCIJXBTZzWIksWkUluC2MwGHov/srE+GPhpIW0aivP73o+DFIZ3KRDBSMiVwIbgP+zX88UETN/NRgMnSJQmRhfZo+cTXpKuokm6wU4mcHcDZwHnARQ1Q3AaPdEMhgMvY3GlkaO1x93ZCKLkRiunHglL+x6gabWpjBIZ3ALJwqmRVVPdaVzEblURHaIyG4R+Z6f44ki8rh9vFRERtv7R4tIvYhssLcHvM5JEJEHRWSniGwXkcX2/ptE5IjXOV/siswGgyH0tCdZOpjBgGUmq22q5fX9r7solcFtnNQi2yIiy4BYEZkA3I5VNiYoIhIL/AH4FFAOvC8iq1R1m1ezLwAnVHW8iFwPeJYGANijqjP9dP194LCqThSRGGCo17HHVfU2B+/JYDCEkY7KxPhy8ZiL6Rffj1U7VnHJuEvcFM3gIk5mMF8HcrEKXT4G1ADfcHDeecBuVd2rqk3ACmCRT5tFgKcUzVPAxeK9EpF/bgF+BqCqbap61IEsBoMhgnRUJsaX5PhkLhl3Cat2rEJV3RTN4CIdKhhVPaOq31fV2apaaD9vcND3SOCg1+tye5/fNqraApwCPFlYY0RkvYi8ISJFACIy2D72ExH5QESeFJERXv0ttkvZPCUio/wJJSJfFpG1IrL2yBGzBrjBEA46KhPjj4UTF3Kw5iAbD210SyyDyziJIisUkWL7ht6ZWmT+ZiK+f0UCtakCslU1H/gW8KiIDMQy6WUBb6tqAfAu8Ev7vNXAaFWdDrzMRzOjsztXfdBWlIWpqakO3obBYOguVbVVxMXEMbzfcMfnXD7xcgThme3PuCiZwU2cmMgeAR4GFgNXem0dUQ54zyKygMpAbUQkDhgEHFfVRlU9BqCq64A9wETgGNb6NCvt858ECux2x1TVs17NQ8AsBzIaDIYwUFlX2WEWvy9p/dOYO2quCVfuwTj5to+o6ipV3dfJWmTvAxNEZIyIJADXY60t480q4Eb7+RLgVVVVEUm1gwQQkbHABGCvWsbY1cBF9jkXA9vsdt7G3YVAmQMZu8SKLSuY99d5tGmbW0MYDL2KqtoqxxFk3iyatIgPqj6gvKbcBakMbuNEwfxIRP4kIktF5GrP1tFJtk/lNuBFrJv9E6q6VUTuEZGFdrM/A8NEZDeWKcwTyjwP2CQiG7Gc/7eq6nH72HeBu20z3eeAb9v7bxeRrfY5twM3OXhvXeJ002nWfLiG/Sf3uzWEwdCrcFomxpeFk6xbhalN1jNxEqZ8MzAZiAc8f9kVKO7oRFV9HnjeZ99dXs8bgGv8nPc08HSAPg9gKSDf/XcCd3YkUyjITcsFYMvhLaakuMHggKq6Ki4YdUGnz5s0bBIThk5g1Y5VfHX2V12QzOAmThTMDFWd5rokPYipqVMB2Hp4a/s/LIPB4J+m1iaOnjnapRmMiLBo0iJ+U/obahprGJg40AUJDW7hxERWIiJTXZekBzEwcSDZg7LZemRrpEUxGKKe6rpqwHkOjC8LJy2kua2Zf+35VyjFMoQBJwrmQmCDXfJlk2cJZbcFi3ZyU3PZcnhLpMUwGKIeTw5MV5z8AHNHzWVY8jCe2WHClXsaTkxkl7ouRQ8kNzWXV/e9SmtbK7ExsZEWx2CIWjpbJsaXuJg4rph4Bat2rKKlrYW4GCe3LUM0EHAGYyc2AtQG2Po0eWl5NLY2sufEnkiLYjBENZ0tE+OPhZMWcqLhBG9/+HaoxDKEgWAmskftx3XAWvtxndfrPo0nkmzrYeOHMRiCUVlbSazEktqv65UzLhl3CQmxCcZM1sMIqGBU9Qr7cYyqjrUfPVufj82dMnwKgPHDGAwdUFVbxYiUEd0yJackpHDxmItN8csehpNaZK842dfX6J/Qn7FDxppIMoOhAyrrupZk6cuiSYvYc2IPZUddK9JhCDHBfDBJIjIUGC4iQ0RkqL2NBrp/tfQCclNzjYIxGDqgq2VifLli4hUApvhlDyLYDObfsPwtkznb//IM1kJifZ7c1Fx2HN1Bc2tzpEUxGKKWrpaJ8WXkwJEUZhaa4pc9iGA+mN+o6hjg3318MDNU9fdhlDFqyU3LpbmtmV3Hd0VaFIMhKmlubebImSMhmcGAZSYrLS9tT940RDdOFhz7XTgE6YnkpeUBJpLMYAiERxGEYgYDVriyojy387mQ9GdwF+eLMxjOYfLwycRIjIkkMxgCEIocGG+mpU0jZ1COCVfuIRgF0w2S4pIYN2SccfQbDAHobpkYXzzFL1/a+xJnms+EpE+DezhSMCIyUkQ+JiLzPJvbgvUU8tLyjIIxGALQ3TIx/rhy0pU0tDTw+v7XQ9anwR06LOojIj8HrsNaObLV3q3Amy7K1WPITc1l1Y5VNLY0khiXGGlxDIaooqquihiJIa1/Wsj6nJM1B0FYW7mWT0/4dMj6NYQeJ1XjrgImea13b/AiNy2XVm1lx7EdTB8xPdLiGAxRRWVtJSP6dy+L35eUhBQmDpvIB1UfhKxPgzs4MZHtxVrN0uAHE0lmMASmqq4qZA5+bwoyClhfvT7k/RpCi5MZzBms9WBeAdpnMap6u2tS9SAmDptIXEyc8cMYDH6orK0ka2BWyPvNT8/nsS2PcezMMYb1Gxby/g2hwYmCWWVvBj8kxCYwYegEE6psMPihqraK2ZmzQ95vQUYBAOur1/PJsZ8Mef+G0NChglHVv4lIAjDR3rVDVU1tFC9y03LZUL0h0mIYDFFFS1sLh08fDmkEmYf8jHwAPqj6wCiYKMZJNeWLgF1Y9cf+COw0Ycpnk5eax57je6hvro+0KAZD1HCo7hCKhiwHxpuhyUPJGZRj/DBRjhMn/6+AS1R1vqrOAxYA97krVs8iNy0XRU0ZcYPBC0+SpRszGLBmMSaSLLpxomDiVXWH54Wq7sRElZ1FbqpZ3dJg8CXUZWJ8KUgvYNexXdQ29vkV3KMWJwpmrYj8WUQusreHsMr2G2zGDx1PQmyCiSQzGLwIxwxGUTYe2uhK/4bu40TBfAXYCtwO3IGV0X+rm0L1NOJj45k0bJJRMAaDF1W1VQgS0ix+b9ojyaqMHyZacRJF1gj82t4MAchNy6WkvCTSYhgMUUNlbSVp/dOIi3GSDdF5MlIySOufxgfVxg8TrQRbMvkJ+3GziGzy3Zx0LiKXisgOEdktIt/zczxRRB63j5fayzEjIqNFpF5ENtjbA17nJIjIgyKyU0S2i8jiYH2Fi7zUPPaf3E9dU104hzUYopaquirXzGNgVVYuyCgwM5goJthfizvsxyu60rGIxGKFNn8KKAfeF5FVqrrNq9kXgBOqOl5Ergc8hTUB9qjqTD9dfx84rKoTRSQGGOqgL9fJTbMc/WVHypg9MvSJZQZDT8OtMjHe5Kfn8/Lel02x2Sgl2JLJVfbTr6rqAe8N+KqDvs8DdqvqXlVtAlYAi3zaLAL+Zj9/CrhYRKSDfm8BfmbL2KaqR7vRV8jwRJKZjH6DwaKytpLMFPdmMGD5YVraWszvLkpx4uT/lJ99lzk4byRw0Ot1ub3PbxtVbQFOAZ7CQmNEZL2IvCEiRQAiMtg+9hMR+UBEnhSREQ76akdEviwia0Vk7ZEjRxy8DWeMHTKWpLgk4+g3GPgoiz8cMxjA5MNEKcF8MF8Rkc3AJB//yz7AiQ/G3+xBHbapArJVNR/4FvCoiAzEMullAW+ragHwLvDLToyHqj6oqoWqWpiamurgbTgjNiaWKcOnGAVjMACHTx+mTdtc9cGA9cduUOIgk9EfpQTzwTwKvIBljvJ20Neq6nEHfZcDo7xeZwGVAdqUi0gcMAg4rqqKXblZVdeJyB6sWmjrsKo7r7TPfxLL9xKwLwdyhozctFyzyp7BwEcrWbpRJsYbEWFm+kwzg4lSgvlgTqnqflVdavtd6rFmBCkiku2g7/eBCSIyxi6WeT3nVmVeBdxoP18CvKqqKiKpdpAAIjIWmADstRXPauAi+5yLsfJyAvblQM6QkZuaS3lNOacaToVzWIMh6nA7ydKbgowCNh3aREtbi+tjGTqHk2KXV4rILmAf8AawH2tmExTbD3Ib8CJQBjyhqltF5B4RWWg3+zMwTER2Y5nCPDOlecAmEdmI5bC/1WvW9F3gbjtU+nPAtzvoK2x4Fh/bdmRbBy0Nht6N22VivMlPz6e+pZ4dR3d03NgQVpxkQN0LzAFeVtV8Efk4sNRJ56r6PPC8z767vJ43ANf4Oe9p4OkAfR7AUkC++/32FU7aa5Id2crcUXMjKYrBEFEqaysRhBH9R3TcuJt4rw3jSRcwRAdOosiaVfUYECMiMar6GuAvP6XPkzM4h37x/UzIpKHPU1VbRWr/VOJj3a+LO2n4JJLikowfJgpxMoM5KSIpwJvAIyJyGDDGTj/ESAxTU6eaSDJDn6eyrtJ1B7+HuJg4ZoyYYSLJohAnM5hFWJFb3wT+D9gDXOmmUD2ZvLQ8U7bf0OepqnW3TIwv+en5rK9aT5jjegwdEFTB2JFcz9gZ8y2q+jdV/a1tMjP4ITc1l6q6Ko7XhzVC2mCIKqrqqsI2gwHLD3Oq8RT7Tu4L25iGjgmqYFS1FTgjIoPCJE+Pxyw+ZujrtLa1Ul1XHd4ZTIbJ6I9GnJjIGoDN9qJjv/VsbgvWU/GEKhs/jKGvcuTMEdq0LSwhyh7y0vKIlVhTWTnKcOLkf87eDA7IGpjFwMSBJpLM0GcJZ5Klh6S4JHLTcs3aMFGGkwXH/tZRG8NHiIiJJDP0acJVJsaX/PR8Xtj9AqpKGAupG4LgJJN/n4js9d3CIVxPJS/VRJIZ+i6RmMGA5eg/fPpwexUBQ+Rx4oMpBGbbWxHwW2C5m0L1dHLTcjly5giHTx+OtCgGQ9jx3OBHpLifxe+Np3S/8cNEDx0qGFU95rVVqOr9wCfCIFuPxUSSGfoylbWVpPZLJSE2Iazjzky3CoyYhMvowYmJrMBrKxT9cmrLAAAgAElEQVSRW4EBYZCtx+Kph2T8MP4prynnOy99h+bW5kiLYnCBcCyV7I8BiQOYMHSCCVWOIpxEkf3K63kLVjXla12RppeQkZLBkKQhZgYTgF+98yvuL72fKydeSVFOUaTFMYSYytrwlYnxpSCjgNKK0oiMbTgXJyayj3ttn1LVL6mqqYsdBBEhNy2XLUdMqLIvLW0trNi6AoB1VesiLI3BDcJdJsab/PR89p/cbyppRAkBZzAi8q1gJ6rqr0MvTu8hNzWXJ7Y+YUImfXh136tU11UDsLZybYSlMYQaTxZ/JGcwABuqN/CJMcZVHGmCzWAG2Fsh8BVgpL3dCkx1X7SeTV5aHicaTrTfTA0WyzctZ3DSYBaMW2AUTC/k6JmjtGpr5GYwpmRMVBFwBqOqPwYQkX8BBapaa7++G3gyLNL1YDyRZFsOb4mIwzMaOd10muKyYpZNW0b2oGxe3PMiNY01DEwcGGnRDCEinCtZ+mN4v+GMGjjKRJJFCU7yYLKBJq/XTcBoV6TpRZhIsnN5ZscznG4+zQ3Tb6AwsxAw/zR7G5FKsvQmPyPfXFdRghMF8w/gPRG5W0R+BJQCpnxMB6T1TyO1X6qJJPNi+ablZA/K5sLsC5mVMQuAdZXG0d+biFSZGG8K0gvYcXQHp5tOR0wGg4WTKLL/BG4GTgAngZtV9WduC9YbyE3LNTMYm0N1h/jXnn/x2WmfJUZiSO2fSvagbNZWGT9Mb8Izg0lPSY+YDPkZ+SjKxkMbIyaDwcLJDAZV/UBVf2NvxrjpkNxUS8GYVfbg8a2P06qt3DD9hvZ9hZmFxtHfy6iqq2JY8jAS4xIjJoMnksyUjIk8jhSMoWvkpuZS01hDeU15pEWJOI9sfoSZ6TOZmvpRAGJhRiG7j+/mRP2JCEpmCCWVtZUR9b8AjBwwkuH9hhs/TBRgFIyLmMXHLHYe28l7Fe9xw7QbztpvHP29j0iVifFGRCjIKDCRZFGAUTAu4okk6+uLjz2y6REEYem0pWftn5VpOfqNmaz3EA0zGLAy+rcc3kJTa1PHjQ2u4aTYZa2I1PhsB0VkpYiMDYeQPZWhyUNJT0nv0zMYVWX55uVcPPbic248Q5OHMmbwGFMyppfQpm0RzeL3piCjgOa2ZhPFGWGczGB+Dfw/rCz+LODfgYeAFcBf3BOtd5CX1rcXHyspL2Hvib3nmMc8GEd/7+HomaO0tLVEhYLxrA1jzK+RxYmCuVRV/1dVa1W1RlUfBD6tqo8DQ1yWr8fjiSRr07ZIixIRlm9aTnJcMp+Z8hm/xwszC9l3ch/HzhwLs2SGUOPJgYkGE9m4oeMYkDDA+GEijBMF0yYi14pIjL15l+oPGn8rIpeKyA4R2S0i3/NzPFFEHrePl4rIaHv/aBGpF5EN9vaA1zmv2316jqXZ+28SkSNe+7/o5ANwm9zUXM40n+HAyQORFiXsNLU28fjWx1k0eVHAcjAeR78xk/V8Il0mxpsYiWFm+kwzg4kwThTMZ4HPAYeBQ/bzG0QkGbgt0EkiEgv8AbgMqzjmUhHxLZL5BeCEqo4H7gN+7nVsj6rOtLdbfWXyOua9LvHjXvv/5OC9uU5fjiR7cfeLHKs/xmenfTZgG0/OgjGT9XyioUyMNwUZBWw8tJHWttZIi9JncZLJv1dVr1TV4aqaaj/frar1qvpWkFPPA3bb5zdh+WwW+bRZxEdlZ54CLpZeVtvek/fRF/0wj2x+hGHJw1gwbkHANoOTBjNh6AQzg+kFeExkkczi9yY/PZ8zzWfYeWxnpEXpsziJIksVkf8QkQdF5C+ezUHfI4GDXq/L7X1+26hqC3AKGGYfGyMi60XkDRHxXfbwr7YZ7Ic+CmmxiGwSkadEZFSA9/NlEVkrImuPHDni4G10j0FJg8gamNXnFh+raazhmR3PcH3e9cTHxgdtOytzlpnB9AIqaysZmjyUpLikSIsCeGX0Gz9MxHBiInsGGAS8DDzntXWEv5mIr88mUJsqIFtV84FvAY+KiMeI/1lVnQYU2dvn7P2rgdGqOt2W1W9BTlV9UFULVbUwNTXVwdvoPrmpuX1uBlNcVkxDS8NZpWECUZhRyIenPuTw6cMdtjVEL1V1VVERQeZh8vDJJMYmGj9MBHGiYPqp6ndV9QlVfdqzOTivHPCeRWQBlYHaiEgcliI7rqqNqnoMQFXXAXuAifbrCvuxFngUyxSHqh5T1Ua734eAWQ5kDAt5aXmUHS3rU7bg5ZuWM27IOM4feX6Hbdsd/aayco8mWpIsPcTHxjN9xHQzg4kgThTMsyLy6S70/T4wQUTGiEgCcD2wyqfNKuBG+/kS4FVVVdssFwtgJ3NOAPaKSJyIDLf3xwNXAFvs195/nRYCZV2Q2RVyU3NpaGlg74m9kRYlLFTUVPDqvle5YfoNjpaLzs/IRxBjJuvhREOZGF/y0621YUzB2cjgRMHcgaVk6u0s/loRqenoJNunchvwItbN/glV3Soi94jIQrvZn4FhIrIbyxTmCWWeB2wSkY1Yzv9bVfU4kAi8KCKbgA1ABdZsBeB2Edlqn3M7cJOD9xYW+triY49teQxFg0aPeTMwcSCThk8ypft7MKpKVW0VmSnRM4MByw9zsuEkB071vTSBaCDgkskeVHVAVztX1eeB53323eX1vAG4xs95TwPnmOFU9TQBTF+qeidwZ1dldRPvSLKrJl8VYWncZ/mm5Zw/8nwmDJvg+JxZGbN4ff/r7gllcJVj9cdobmuOvhlMxkcZ/aMHj46sMH2QgDMYEZlsPxb428InYs8nJSGF0YNH94kZzJbDW9h4aKPj2YuHwsxCKmor2kNdDT0LTw5MNDn5AaalTSNWYs3aMBEi2AzmW8CXgV/5OabAJ1yRqJeSm5rbJ6oqP7LpEWIlluvyruvUed4Z/VcMuMIN0QwuEk1lYrxJjk9mSuoUPqg2kWSRIKCCUdUv248fD584vZe8tDxe2vsSLW0txMV0aJnskbRpG49sfoQF4xeQ1j+tU+fOTJ9JjMSwtnItV0w0Cqan0T6DiTITGViO/pf3vhxpMfokjtaDEZGPicgyEfm8Z3NbsN5GbmouTa1N7D6+O9KiuMaaA2s4WHMwYOXkYKQkpDBl+BQTSdZDaa9DFmUmMrAc/VV1VVTXVUdalD6Hk0z+fwC/BC4EZttbocty9Tr6wuJjyzctJyUhhUWTfSsCOcNTut+ElLrPh6c+DGl/VbVVDE4aTHJ8ckj7DQWe0v3GDxN+nMxgCoELVPWrqvp1e7vdbcF6G5OHT0aQXpvR39DSwJPbnuTqKVfTL75fl/qYlTGLQ6cPtZtbDO7wzsF3yLk/J6Rmo8q66Eqy9GZm+kzArA0TCZwomC1AdFSv68H0i+/HuKHjem0k2XM7n+NU46kumcc8eBz9xkzmLp5w8L9t9FtNqUtU1UZXmRhvBiUNYtyQcSajPwI4UTDDgW0i8qKIrPJsbgvWG+nNkWTLNy8nPSWdT4zpenDhjPQZxEqsUTAuU1pRCsDKspWcaT4Tkj6jrUyMLwUZBWYGEwGcKJi7gauAn2KFLHs2QyfJTc1l1/FdNLU2RVqUkHK8/jjP7XyOpXlLiY2J7XI//eL7kZuWazL6XURVKS0vZdyQcZxuPs2zO58NSZ/RVujSl/z0fPad3MeJ+hORFqVP4WQ9mDf8beEQrreRl5ZHS1tLr1uf4qltT9Hc1uyocnJHFGZEv6O/7EgZsx+aTdmRqCl355gPT33IodOHuOP8O8hIyeDRzY92u8/j9cdpam2K+hkMwIbqDRGWpG/hJIrsahHZJSKnOlOLzHAu7TXJepmjf/mm5UwZPqU9Wqc7zMqcxdEzRzlYc7DjxhFi9c7VrK1cy5Inl3C66XSkxekUHvPY3FFzuT7vel7Y/UK3/9VH01LJgfCUjDF+mPDixET238BCVR2kqgNVdYCq+l9g3RCUScMmESuxvcoPs//kftZ8uMZx5eSO6AmO/nfL32VQ4iDKjpTxlee+EtWzLV9Ky0tJjE1k+ojpLJu2jKbWJorLirvVZ7QtleyPtP5pjBww0vhhwowTBXNIVXueLSAKSYxLZMKwCb0qksxjYlk2bVlI+ps+YjpxMXFRq2BUlZLyEhZOWsjdF93NPzb9gz998KdIi+WY0opSZmXOIiE2gVkZsxg/dDyPbumemcxTJiaafTBgzWLMDCa8OFEwa0XkcRFZapvLrhaRq12XrJeSm5rbaxSMqvKPTf+gKLsoZJVqk+KSmJY2LWoVzIenPqS6rpo5WXP4wbwfcMm4S/j6C1/vEbb95tZm1lWta18ETkRYlreM1/a91q0io9FcJsabgvQCth/dHrLIOUPHOFEwA4EzwCXAlfZmikV1kdzUXHYf301DS0OkRek266vXs/3o9pA4972J5oz+kvISAOZkzSFGYlj+meUM7zecJU8s4VTDqQhLF5xNhzbR0NJw1iqjS6ctRVEe3/p4l/utqqtiUOKgLifYhov8jHzatI1NhzZFWpQ+g5Mospv9bLeEQ7jeSG5aLm3axvaj2yMtSrdZvmk58THxLJm6JKT9FmYWcqLhBPtO7gtpv6GgpLyE5LhkpqVNAyC1fyqPL3mc/Sf3c8uqW6JSKXrwOPjPz/pIwUwePpn89Hwe2/JYl/uNxpUs/eGJJDMlY8KHkyiyv4rIX3y3cAjXG8lLywN6fiRZa1srj215jMsnXs7Q5KEh7XtWhrWm3LrKdSHtNxSUVJRQmFlIfGx8+74Lsi/g55/8OcVlxfy29LcRlC44pRWlpPVPI2dQzln7l+Yt5b2K97pciDXakyw9jBo4iqHJQ42jP4w4MZE9Czxnb69gmczq3BSqNzNh6ATiY+J7fCTZq/tepbquululYQKRl5ZHQmxC1PlhGlsa+aDqA+ZkzTnn2LfmfotFkxbx7y/9e7sZLdooLS/l/JHnnxPtd33e9QCs2LKiS/1Gc5kYb0SEgowC4+gPI05MZE97bY8A1wJ57ovWO4mPjWfisIk93tG/fPNyBiUO4vKJl4e878Q4K4w22jL6N1RvoKm1ya+CEREevuphRg0cxbVPXsuxM8ciIGFgTtSfYMexHWf5XzyMGjSKouwiHt38aKdNfKraY2YwYGX0bz68mebW5kiL0idwtB6MDxOA7FAL0pfIS8vr0QrmdNNpisuKuWbqNSTFJbkyRmFGIesq19Gmba703xW8Hfz+GJw0mCeveZJDpw/xuZWfiyrZ3698Hzjb/+LNsmnLKDta1mkH+MmGkzS2NvaIGQxYfpim1ia2HdkWaVH6BE58MLV2Bn+NncG/Gviu+6L1XnJTc9l3Yh91TT3T0rh652rqmur47PTPujZGYWYhpxpPsef4HtfG6CwlFSWMGjgq6L/1WZmzuH/B/byw+wX+663/CqN0wSktL0UQZmfO9nt8ydQlxMXEdbp0TE9IsvTGU23C+GHCQ1AFI5axNtfO4PdsE1X16TDJ1ys5b+R5KBq1tvqOeLrsadJT0pmXM8+1MTwZ/euqosfRX1JeEnD24s2thbeyNG8pP3zth+2l8SNNaUUpk4dPZlDSIL/Hh/cbziXjLmHF1hWdmnn1hDIx3kwYNoGUhJQe64dpbGnkF2//glH3jeLVfa9GWpwOCapg1DLIrgyTLH2GuaPmEiMxrDmwJtKidJr65nqe3/U8V026ihjpioXVGVNTp5IYmxg1jv7qumr2n9zP3Ky5HbYVEf73iv9lwtAJXP/U9RFfqldVKa0oDWge87AsbxkfnvqQdw6+47jvnjaDiZEYZoyY0eNmMKrK6h2ryfufPL7z8neoqKngya1PRlqsDnFyhygREf/zakOXGJg4kJnpM1nzYc9TMC/tfYkzzWe4eoq7xRziY+OZmT4zahRMR/4XXwYkDuCpa5+iprGGpU8vpbWt1U3xgrLv5D6Onjnq18HvzaLJi0iOS+6UmaynlInxpiCjgA3VG6LKRxaMrYe3smD5AhauWEisxPL8sue5dPylvHEg+ovaO1EwHwfeFZE9IrJJRDaLiEmF7SZF2UWUlJf0uLVhisuKGZw0mItGX+T6WIWZhayrig5Hf0l5CfEx8e1VeZ2Ql5bH/1z+P7y+/3V+9PqPXJQuOKXldoJlBwomJSGFhZMW8uS2Jx1HWVXWVjIgYQD9E/p3W85wkZ+ez+nm01G/3MLx+uPc/sLtzHhgBu9VvMd9C+5j81c2c9mEy5ifM5+yo2UcPn040mIGxYmCuQwYB3yCj8rEXOmmUH2Bouwi6lvqe9RUvbm1mVU7VrFw0sKzEg3dojCzkLqmuqhYP6ekvIT8jPxOR83dOPNGvpD/Bf5zzX/ywq4XXJIuOKUVpVb1gRHTOmy7NG8pR88c5eW9Lzvqu6quqseYxzx4TIUFDxZw2SOX8cf3/8jBU9GzPERLWwt/eO8PTPjdBP7w/h/4UsGX2PX1XXxjzjfaf3fzR88H4M0Db0ZS1A5xkgdzwN8WDuF6MxdmXwjQo/wwbxx4gxMNJ7h6cnhqnUZL6f6Wthber3yfOSOdmcd8+d1lv2PGiBncsPKGiNzIPBWU42LiOmx76fhLGZw02HHpmMrayh7j4PcwNXUqb938FrfNvo3dx3fztee/Rvb92RT8bwE/eu1HrKtcF7GSPy/vfZmZD8zkthduY8aIGaz/t/X8zxX/Q2r/1LPazcqYRb/4fj1fwXQHEblURHaIyG4R+Z6f44l2pebdIlIqIqPt/aNFpF5ENtjbA17nvG736TmWFqyvaGVEyggmDpvYo/wwxWXF9IvvxyXjLgnLeJOHTyY5LjniJWO2HN7CmeYzjv0vviTHJ/PkNZbZ6dqnrg2rWbSptYn1Ves7NI95SIxLZPGUxazcvtJR1eGeOIMBq7zPrxb8ip237aTsa2X8/JM/p39Cf+5dcy+FDxWSdV8Wtz57K8/tfI765nrX5dl9fDdXrbiKT/3jU5xpPsPT1z7NK59/hekjpvttHx8bz8dGfSzq/TCuKRgRiQX+gGVimwosFZGpPs2+AJxQ1fHAfcDPvY7tUdWZ9narz3mf9Tp22EFfUUlRdhFvffhWVPgYOqJN21i5fSWXjb+M5PjksIwZFxNHfkZ+xDP6O+vg98eEYRP4y6K/UFJewvdePue/lmtsrN5IY2ujYwUDVtJlXVMdz+18Lmg7Ve0xZWICISJMHj6Z71zwHdbcvIbqb1fz8KKHmZs1l+WblnPFY1cw/BfDuWrFVfxl/V84VHcopOPXNNbw3Ze+S+4fc3l578v87OKfse1r27h6ytUdLuA3P2c+mw9t5nj98ZDKFEo6njN3nfOA3aq6F0BEVgCLAO8U2kXA3fbzp4DfS9eXRfTbl0Zxedui7CL+vP7PbD281ZF9PJKUlJdQXVftevSYL4UZhfxp/Z9obWslNiY2rGN7KCkvIa1/WrfXvFkydQm3n3c795Xcx4XZF4bls/RXQbkj5ufMJyMlg0e3PMo1udcEbHeq8RT1LfU9cgYTiNT+qdw480ZunHkjDS0NvL7/dVbvWM2qnat4ZsczCML5Wedz+YTLyRqYRf/4/vSL70f/BPvRfu3ZlxyX7Pe6bdM2Ht7wMP/xyn9w6PQhbpp5Ez/9xE87ZW6cnzMfRVlzYA2LJi8K5ccQMjpUMPbiYj8H0gCxN3WwbPJIwNvgXA74XuXtbVS1RUROAcPsY2NEZD1QA/xAVb1tSX8VkVbgaeBeW4kE6uuoz/v5MvBlgOzsyFa8KcopAmDNh2uiXsEUlxUTHxPP5RNCX3ssGIWZhfz2vd+y/eh2ctNywzq2B0+CZSiWhP7FJb+gpKKEm5+5mTlZc1y/OZdWlJKeks6ogaMcnxMbE8t1udfxx7V/5GTDSQYnDfbbrieGKHeGpLgkLh1/KZeOv5Tff/r3bDy0kVU7VrF652p++NoPO9WPt/Lpn9CfmsYadh/fzdysuaxeuprZIzufCTJ75GwSYxN588CbPVfBAP8NXNmFZZP9/Rp9ZxOB2lQB2ap6TERmAf8UkVxVrcEyj1WIyAAsBfM54O8Ox0NVHwQeBCgsLIzo7GbM4DFkDshkzYdr+Orsr0ZSlKCoKiu3r+STYz8ZMBPcLbwd/ZFQMMfrj7Pj2A5unHFjSPpLiE3g4UUPM/WPU3l8y+N8c+43Q9JvIAJVUO6IZdOWcX/p/RSXFXNLvv/ln3pakmV3EBFmps9kZvpM7pp/FyfqT3Cy4SSnm09zpvkMp5vsR/u1v33ex1L7pfLji37M0rylXf7jkhSXxJysOVHth3GiYA51QbmANWPx/tuUBVQGaFMuInHAIOC4PSNpBFDVdSKyB5gIrFXVCnt/rYg8imWK+3ugvrogd9gQEYqyi1hzYA2qGpJ/yG6w6dAm9p7Yy50X3hn2sScOm0hKQgrrqtZx48zQ3OQ7w3sV7wHd87/4MiV1CjNGzODpsqddVTDH64+z6/gubp55c6fPLcwsZNyQcTy6+dGACqanlYkJJUOShzAkeUikxWB+znzuXXMvpxpOhf3PnxMCOvlF5GrbPLbWjs5a6tln7++I94EJIjJGRBKA64FVPm1WAZ67xhLgVVVVEUm1gwQQkbFYFZz3ikiciAy398dj5eRsCdaXAzkjSlF2ERW1Few/uT/SogSkuKyYGIlh4aSFYR87NiaW/PT8iIUql5SXECMxXTJhBGPxlMW8ffDt9lmAG3iUY2f8Lx5EhGXTlvHa/tfaTWG+eGTvrSaynsD80fNp0zbePvh2pEXxS7AosivtbSBwBrjEa98VHXWsqi3AbcCLQBnwhKpuFZF7RMRzp/ozMExEdgPfAjzhNfOATSKyEcthf6uqHgcSgRftSgIbgArgoQ76imo8BSOjOVy5eHsxRdlFpPVPi8j4hZmFrK9eT0tbS9jHfrf8XaalTSMlISWk/XqWmV5Z5l6pP08FZY+ZsbMszVtKm7bxxNYn/B6vqq0iJSGFAYkDuiOmoRvMyZpDfEx81ObDBDSRqWrn59Xn9vE88LzPvru8njcA54Sp2NWaz6nYrKqngVkBxvLbV7STm5bLkKQhrDmwhs/P+HykxTmHncd2suXwFu5fcH/EZCjMLKShpYFtR7YFzAtwgzZto7S8tH3Fx1AyJXUKU4ZP4amyp/jaeV8Lef9gOfinpk5lYGJH8Tj+mZI6hZnpM3lsy2PcMeeOc45X1lWa2UuE6Rffj9kjZ0etH8bJejB/E5HBXq+HiMhf3BWr7xAjMVyQfUHUzmA8/7A/M+UzEZMhUhn9O47u4FTjqZD6X7xZMnUJbx5405V6UqrKexXvdSr/xR/L8pZRWlHqd12eqtqemWTZ25ifM5+1lWs53XQ60qKcg5NEy+mqetLzQlVPAM4r/hk6pCi7iB3HdkRl4bri7cUUZhaSPShyId3jh45nYOLAsCuYUCRYBmPxlMW0aRv/3P7PkPe958QejtUf65L/xZvr8q4DYMWWFecc64llYnoj83Lm0dLW0qllFsKFEwUTIyLt4RIiMhR3EzT7HEXZVj7MWx++FWFJzqa8ppz3Kt4LW+2xQMRIDLMyZoV98bGS8hIGJw1m4rCJrvQ/fcR0xg8dz9NloV+/z2kF5Y7IHpRNUXYRj2559Kz6XKpqlYlJMTOYSHPBqAuIldio9MM4UTC/At4RkZ+IyD3AO8Av3BWrbzErcxbJcclRV/jS88863Nn7/piVMYuN1RvDWserpKKE80ee79rCaiLC4imLeXXfqyEv91FaUUq/+H4hyR1amreUbUe2sfnw5vZ9tU21nGk+Y2YwUcCAxAEUZBREpR/GSTXlvwOLgUPAEeBqe58hRCTEJnB+1vlR54cpLitmaupUJg2fFGlRKMwspLG1ka2Ht4ZlvNrGWrYc3uKaeczDkqlLaGlrYdUO3wj+7lFaUUphZqGjCsodcU3uNcTFxJ21EFlfSrLsCczPmU9pRWlYCnN2BidO/n+o6jZV/b2q/k5Vt4nIP8IhXF+iKLuI9dXrqW2sjbQoABw9c5Q3DrwRcfOYh3A7+tdWrqVN21xXMLMyZpEzKIentj0Vsj4bWxrZUL2h2+YxD8P7DedTYz/Fii0r2guz9vYyMT2NeTnzaGptas99ihaczP3PmmPbCZB+Q4UNXacou4g2bePd8ncjLQoAq3asok3bosI8BjB2yFgGJw0Om4LxOPjPG3meq+N4zGQv7X2JUw2nQtLnhuoNNLU2hUzBgFU65sCpA7x70Lo+zQwmuijKKUKQqDOTBcvkv1NEaoHpIlIjIrX268PAM2GTsI8wd9RcYiU2avwwxWXF5AzKYWb6zEiLAlg3Ys8SyuGgpKKEScMmMTR5qOtjLZ66mKbWJp7d+WxI+utKBeWOWDRpEUlxSe1msr5cJiYaGZw0mBnpM3qOglHVn6nqAOAXqjpQVQfY2zBVDX9Rql5OSkIK+Rn5UeGHqWms4aW9LzlakyKczMqYxaZDm2hsaXR1HFVtr6AcDjxVlUMVTVZaUUrmgEyyBmaFpD+wHMkLJy3kyW3WwmmVtZX0j+/PgASTxR8tzM+Zz7sH3w1rIExHOHHy32knV54nIvM8WziE62sUZRdRWlHq+g20I57f9TxNrU1RYx7zUJhZSHNb81nRTG6w7+Q+Dp8+zNysua6O4yFGYrh68tW8sPsF6prqut1faXmpK8pxWd4yjpw5wiv7XqGqroqMARlR9QekrzMvZx71LfURX2LcGydO/i8Cb2LVFPux/Xi3u2L1TYqyi2hoaQh7vocvxWXFjOg/Imw3WKeEy9HvdoKlP5ZMXUJDSwMv7HqhW/0cPXOUPSf2hNT/4uHS8ZcyOGkwj215jMraSuN/iTI8dQ3f2B89ZjInTv47gNnAAVX9OFYW/xFXpeqjXJh9IUBE/TANLQ08v+t5rpp8VcRWkAxEzqAchiUPC4uC6R/fP6zrz1yYfSFp/dN4qqx70WTtFZRdUDCJcYksnrKY4rJi9p3YZyLIoozh/YaTm5obVX4YJwqmwS4kiYgkqg7J9xIAABkySURBVOp2IPKJEb2Q1P6pTB4+OaJ+mJf2vMTp5tNRZx6Djxz94VAws0fODkkOiVNiY2L5zOTP8NzO57qVy1BaXmpVPsh0J9Bzad5S6prqOFhz0CiYKGR+znzePvh2RCqP+8OJgim3i13+E3hJRJ7h3IXDDCGiKLuItw++3Z5vEG6KtxczOGkwF42+KCLjd0RhZiFbj2x1LaGsvrme9dXrmTMyfOYxD4unLOZ082le3PNil/sorSglLy0v5MsLeLho9EWkp6QDJkQ5GpmXM4+6pjrWV62PtCiAMyf/Z1T1pKreDfwQa92Vq9wWrK9SlF3EyYaTbDm8pePGIaa5tZlVO1Zx5cQrSYhNCPv4TpiVMYuWthY2HdrkSv+edWfC6X/xcNHoixiaPLTL0WRt2kZpRakr5jEPsTGxXJdrFcA0IcrRx/zR8wGixkzmqMiSiBSIyO3AdKBcVaMnDq6XUZRjFb6MhB/mzQNvcrz+OJ+ZHLnS/B3htqPf4+APZQ6JU+Jj41k0aRGrdqzqUiThrmO7ONlw0lUFA3BL/i30j+/PjBEzXB3H0HnSU9KZOGxiz1EwInIX8DdgGDAc+KuI/MBtwfoqOYNyyBqYxZsfhr8yanFZMclxySwYvyDsYzsla2AWaf3TWFvlnoIZPXh0uxko3CyZuoSaxhpe2fdKp891I8HSH9NHTKfmzhqmjZjm6jiGrjE/Zz5rDqyhta010qI4msEsBWar6o9U9UfAHOCz7orVdxERirKLWHNgzVnl0d2mTdtYuX0ll024jH7x/cI2bmdx29EfzgRLf1w85mIGJg7sUm2y0vJSUhJSmDJ8iguSnY1bFaYN3WdezjxONZ5yPV/MCU6ukv1AktfrRODc5e0MIaMou4iquir2ntgbtjFLy0upqquKmuKWwSjMKGTbkW0hX8GvoqaCgzUHI+Lg95AYl8jCSQt5ZsczNLc2d+rc0opSZmfOjrrwckN4mZ9j+2GiIB8mWC2y34nIb4FGYKuIPCwifwW2AN1PNzYEpN0PE8Zw5ZXbVxIfE8/lEy8P25hd5eNjPk6btvHQBw+FtF+PiSmSMxiwosmO1x/n9f2vOz6nvrmejYc2uu5/MUQ/owaNYszgMVHhhwk2g1kLrANWAv8BvAa8Dnwf6F66sSEoU1OnMiRpSNgc/apKcVkxF4+9mMFJg8MyZneYnzOfBeMWcPfrd3PkdOhyft89+C4JsQkRL/C5YNwC+sf371Q0mSf6LRLBCYboY17OPN488GZYzez+CFbs8m/BtnAK2deIkRguzL4wbDOYzYc3s+fEnh5hHgPLD3Pfgvuoa6rjrtfuClm/JRUlzMqYRWJcYsj67ArJ8clcPvFyVm5f6dhRG6olkg29g/k58zlWf4xtR7ZFVA7jqYtSirKL2HV8F9V11a6PVVxWjCAsmrzI9bFCxZTUKXxt9td48IMHQ5IT09zazNrKtRE3j3lYMmUJh08f5q0P33LUvrSilFEDR5ncFAMQPfkwRsFEKR4/jNMbTHcoLitur4XVk7j7orsZkjSEb/zfN7ptCth0aBMNLQ1Ro2Aum3AZSXFJjqPJSitKjXnM0M6YwWPIGpjVcxSMiPR3UxDD2RRkFJAcl+y6H2bXsV1sPrw5KmuPdcSQ5CH85OM/4bX9r7Fy+8pu9RWJCsrBSElI4bLxl1G8vbjDskGHTx9m/8n9xjxmaEdEosIP4yTR8mMisg0os1/PEJE/ui5ZHychNoE5WXNc98N4bszRnL0fjC/N+hJ5aXl8+1/fpqGlocv9lFSUkJGSwaiBo0IoXfdYPGUxlbWV7covEMb/YvDH/Jz5VNdVs+v4rojJ4GQGcx+wADgGoKobAbPgWBgoyi5i46GN1DTWuDZGcVkxszJmkTM4x7Ux3CQuJo77F9zP/pP7+fW7v+5yP54Ey2haQOuKiVeQEJvA09uCR5OVVpQSK7GuVVA29EyiIR/GkYlMVQ/67HIU2iIil4rIDhHZLSLf83M8UUQet4+Xishoe/9oEakXkQ329oCfc1eJyBav13eLSIXXOZ92ImM0U5RTRJu28c7Bd1zpv6KmgtKK0h5pHvPm4rEX85nJn+Gna35KZW3nC30fPXOU3cd3R415zMOgpEFcMu4Sni57OqiZo7SilGkjpkV1BQZD+Jk4bCIj+o+IqB/GiYI5KCIfA1REEkTk37HNZcEQkVjgD8BlwFRgqYhM9Wn2BeCEqo7Hmin93OvYHlWdaW+3+vR9Nf6TPe/zOud5B+8tqpmTNYdYiXXND/PP7f8E6PEKBuCXl/yS5rZm7nzlzk6f6zExRZuCActMduDUgYCrnLZpG+9VvGfMY4Zz8Phh3jjwRsT8ME4UzK3A14CRQDkw037dEecBu1V1r119eQXgGwe7CKuQJsBTwMXSgY1CRFKAbwH3OpChR5OSkEJBRoFrfpji7cVMGT6FycMnu9J/OBk7ZOz/b+/Ow6Oo0wSOf98cYDgMp9wd5FCDDgIiytFGUS5lEQyreK0y6oyzOgOirj76LA/DOM+Drq6o4+OOCut44HiADjrI4TGIo4kgciiHBBY0hCvciIKGd/+oCtMm3Z0ipKq6mffzPP2kuvpXXW9+qc6v63cy4fwJPL/8+aMFhldFpUVOFVOb1KtiGnH6CLIyshL2JltbvpZ9h/ZZAWPiKsgroHRfKRv3bAzl/F7WgylX1WtVtZWqnqKq16nqTg/v3Q6IrVordffFTaOqPwJ7cWZtBjhVRD4XkYUiEo055nfAI8DBOOe8XURWiMh0EWkaLygR+YWILBGRJTt2pP7Kz9FIlE83f1qr6duTKT9YzsKNC9O2cT+e+6L30bpRa8bNHXdMC7YVbS6ie6vuNKyXeh0lm+U0Y+CpAxNWkwU1g7JJT2GPh/HSi+zxOI/fiUhNo/Li3YlU/YQkSrMFiKhqT5y7lRkicrKI9AC6qGq8PqlPAZ1x7rC24BRC1d9c9WlV7a2qvVu2bFnDrxC+aF6UQxWHWFy2uE7f9621b1GhFSdE9VilxvUbM+XiKRRvLmbGyhmejqk4UkFxaXFKVo9VGp0/mpJdJXEHlBaXFnNy/ZNPiLtQU/e6texG85zmqVvA4Myk3ANY5z66A82Am0RkapLjSoHYPp/tqb7U8tE0IpIF5AK7VPVQ5V2Sqn6GM3vzaUBf4BwR2Qh8BJwmIn9z021T1QpVPQI8g1NFl/YGRAYAdb8A2aw1s4jkRujVpledvm/Yrj/7es5tey73vHsPBw7XPCfr6vLV7D+8n77t+wYQXe2MPGMkGZIRd26yyhmUbfp8E0+GZBDNi/LhpuDXlwJvBUwXYKCqPqGqTwCXAPnAKGBwkuMWA11F5FQRqQeMAWZXSTMbuMHdHg28r6oqIi3dTgKISCegK7BBVZ9S1baq2hEYAHylqhe66WLnyBiFM+tz2mvRoAXdWnar03aY/Yf2M3/9fK4444qU6pZbFzIkg8eGPkbZ/jKmfDSlxvSpNsAynpYNW1KQV1CtgDn4w0FWbFth7S8mqYK8Ajbs3kDpvtLAz+2lgGkHxFZONwTaqmoFzlT+cbltKrcD83B6nb2qql+KyGQRGeEmmwY0F5ESnKqwyq7MFwArRGQ5TuP/raq6q4Y4HxKRlSKyArgIuMPD75YWopEof//m73W2Qt2zS5/lcMXhE6p6LFbfDn259mfX8vDHD9fYuFlUWkSznGZ0adYlmOBqqTC/kFU7VrF6xz86cC7dspQKrbD2F5NUmONhvBQwDwHLROR/ReQ54HPgYXfqmHeTHaiqc1T1NFXtrKq/d/dNVNXZ7vb3qvqvqtpFVfuo6gZ3/0xVPVNVz1bVXqr6Vpz33qiqZ8U8v15Vf6aq3VV1hKpu8ZoJqS4aibLv0L46WaHu1S9f5c75dzKsyzD6R/rXQXSpacolU8jMyOTuBXcnTZeKAyzjGZU/CkF+chdjI/iNF91bdSe3fm4o7TBeepFNA/oBb7qPAar6rKp+q6rJP72mThxdgOw422HeWfcO1826jv6R/rx+5esndL19+5Pbc2//e3l91esJF+7a+/1eVu1YFeoKll61bdyWfh36/aS7cvHmYvJy82jVqFWIkZlUl5mRyYDIgFDaYbz+h/kep2fWLqCLiNhUMQGK5EaI5EaOqx1m0aZFFL5ayFmnnMXbV7/9TzHq+65+dxHJjTB+7vi41YuLyxajaEq3v8Qa3W00y7ctp2RXCWAzKBvvCvIKWLtzbSDLf8Ty0k35ZuBDnLaU37o/J/kblqkqGomy6OtFtRqRu3TLUoa/PJxIboS5180l96RcHyJMPTnZOTw86GGWb1vOtM+nVXu9qLQIQejTLj06HFa2mc1cNZOtB7by9d6vrXrMeFI5HibouxgvdzDjgHOBTap6EdATSP0RiieYaCTK1gNbWb97/TEdt6Z8DUNeHEKTk5qw4PoFabfmy/Ea3W00F+RdwP3v38+e7/f85LWi0iLyW+anTYEbyY3Qp10fZq6eae0v5pj0bN2ThtkNU7KA+V5VvwdnckpVXQOc7m9YpqratMNs2rOJQS8MIlMyeff6d+mQmzpT0QdFRJg6ZCo7D+5k8sLJR/erqtPAnwbtL7EK8wtZXLaY11a9RlZG1gk3jsn4Izszm/6R/oE39HspYEpFpAlOA/8CEfkL1QdMGp/lt8ineU5zPvza2zeQbQe2cckLl3Dg8AHmXTePrs27+hxh6urZpic397qZJz59gjXlawBYv3s9O7/bmTbtL5UK8wsBmLFyBt1bdScnOyfkiEy6KMgr4IvtX1B+sDywc3rpRTZKVfeo6iTgP3HGroz0OzDzUyLCgMgAT3cwu7/bzeAXB1O2v4y/XvNXzm59dgARprYHBj5Ag+wG3Dn/TiA9BljG07lZZ3q07uF0Tkizuy8TrsrxMH6vkhsraQEjIhmxa66o6kJVne3OjmwCFo1EWb97PVv2Jx7i8+3hb7lsxmWsKV/Dm1e9Sb8O/QKMMHWd0vAUJl4wkTnr5jBn3Rw++eYTGtdrTLeWVVeQSH2j80cDNsGlOTa92/bmpKyTAm2HSVrAuPN6LReRSEDxmCSOtsMk6K586MdDjHplFMWbi3m58GUGdR4UZHgp79fn/ZquzboyYd4EFn29iD7t+pCZkRl2WMfsxh43MvKMkQzrMizsUEwaqZ9Vn77t+wbaDuOlDaYN8KWIvOeuIjlbRKrOKWYC0LN1TxpkN4h7i/vjkR+5ZtY1LNiwgGkjpp2w08Acj3qZ9Xh0yKOs3bmWldtXpl31WKV2J7fjjaveoGXD1J8N3KSWgrwClm1dVq1HpV+yPKT5re9RGE+yM7Pp275vtTuYI3qEW966hVmrZzF1yFRu7HFjOAGmgUu7XsrQLkOZWzI3bQsYY2qroGMBulD56OuPGH7acN/P56WRfyGwEch2txcDS32OyyQQjURZsW3F0W8gqsqEeRN4btlzTCqYxLjzx4UcYWoTEZ689EnG9hjLRR0vCjscYwJ1XrvzqJdZL7B2GC8j+W/BmdH4j+6udjhdlk0IonlRFOXjbz4GYPLCyTxW/BjjzxvPxIKJIUeXHjo17cT0y6en5AqWxvgpJzuHPu36BNYO46UN5jagP7APQFXXAf9cw8FTyPntzycrI4tFmxYxtWgqkxZOYmyPsTwy5JGUnxHYGBO+grwCPiv7jP2H9vt+Li8FzKHYbsnuypPHPiGWqRMNshtwTptzeGbpM9wx7w4K8wt5+l+ePqFnRjbG1J2CvAIqtOJoLYifvPxXWigi9wE5IjIIeA2otj6LCU40EmXndzsZ3HkwL13xElkZXvpqGGOMsyBf60at2f7tdt/P5eU/073ATcBK4JfAHOBZP4Myyd3e53bqZdbjvuh91M+qH3Y4xpg00qheI8omlAVSpS41Tf8uIqOAOaqacHnkdNW7d29dsmRJ2GEYY0xaEZHPVLV3Tem8VJGNAL4SkRdE5DK3DcYYY4xJyss4mLFAF5y2l2uA9SJiVWTGGGOS8nQ3oqo/iMg7OL3HcoDLgZv9DMwYY0x68zLQcqiIPAeUAKNxGvjb+ByXMcaYNOflDuZG4M/AL0/Ehn5jjDH+qLGAUdUxsc9FpD9wjare5ltUxhhj0p6nNhgR6YHTwH8l8H/ALD+DMsYYk/4SFjAichowBrga2Am8gjNuxqagNcYYU6OEAy1F5AiwCLhJVUvcfRtUtVOA8flKRHYAm2p5eAugvA7DqWsW3/Gx+I5fqsdo8dVenqrWuOJdsiqyQpw7mA9EZC5OQ/8JNV2vlwxKRESWeBnJGhaL7/hYfMcv1WO0+PyXsJuyqr6hqlcBZwB/A+4AWonIUyIyOKD4jDHGpCkvI/m/VdWXVHU40B5YhjMBpjHGGJPQMS0ioqq7VPWPqjrQr4DSyNNhB1ADi+/4WHzHL9VjtPh8VuNsysYYY0xt2DKIxhhjfGEFjDHGGF9YAVMDd7LPtSJSIiLVOjeISH0RecV9vVhEOgYYWwcR+UBEVovIlyIyLk6aC0Vkr4gscx8Tg4rPPf9GEVnpnrva6m7ieNzNvxUi0ivA2E6PyZdlIrJPRMZXSRN4/onIdBHZLiJfxOxrJiILRGSd+7NpgmNvcNOsE5EbAortv0Rkjfv3e0NEmiQ4Num14HOMk0Rkc8zf8dIExyb9vPsY3ysxsW0UkWUJjg0kD+uMqtojwQPIBNYDnYB6wHKgW5U0/w78j7s9BnglwPjaAL3c7cbAV3HiuxB4O8Q83Ai0SPL6pcA7OGOszgeKQ/xbb8UZQBZq/gEXAL2AL2L2PQTc627fCzwY57hmwAb3Z1N3u2kAsQ0GstztB+PF5uVa8DnGScBdHq6BpJ93v+Kr8vojwMQw87CuHnYHk1wfoERVN6jqYZzBppdXSXM58Cd3+3XgYglisWtAVbeo6lJ3ez+wGmgXxLnr0OXA8+ooApqISBjLQVwMrFfV2s7sUGdU9UNgV5XdsdfZn4CRcQ4dAixQp7fnbmABMNTv2FR1vqr+6D4twhnOEJoE+eeFl8/7cUsWn/u/40rg5bo+bxisgEmuHfBNzPNSqv8DP5rG/ZDtBZoHEl0Mt2quJ1Ac5+W+IrJcRN4RkTMDDcxZpG6+iHwmIr+I87qXPA7CGBJ/qMPMv0qtVHULOF8sgFPipEmFvPw5zh1pPDVdC3673a3Gm56gijEV8i8KbFPVdQleDzsPj4kVMMnFuxOp2q/bSxpfiUgjYCYwXlX3VXl5KU61z9nAE8CbQcYG9FfVXsAw4DYRuaDK66mQf/WAETjLglcVdv4di1DzUkTuB34EXkqQpKZrwU9PAZ2BHsAWnGqoqkK/FnEmF0529xJmHh4zK2CSKwU6xDxvD5QlSiMiWUAutbs9rxURycYpXF5S1WrLKKjqPlU94G7PAbJFpEVQ8alqmftzO/AGTjVELC957LdhwFJV3Vb1hbDzL8a2yqpD9+f2OGlCy0u3Q8Fw4Fp1Gwuq8nAt+EZVt6lqhaoeAZ5JcO5Qr0X3/8cVODPXxxVmHtaGFTDJLQa6isip7rfcMcDsKmlmA5W9dUYD7yf6gNU1t752GrBaVf87QZrWlW1CItIH52++M6D4GopI48ptnMbgL6okmw38m9ub7Hxgb2VVUIASfmsMM/+qiL3ObgD+EifNPGCwiDR1q4AGu/t8JSJDgXuAEap6MEEaL9eCnzHGtuuNSnBuL593P10CrFHV0ngvhp2HtRJ2L4NUf+D0cvoKp3fJ/e6+yTgfJoCTcKpWSoBPgU4BxjYA5xZ+Bc4cccvceG8FbnXT3A58idMjpgjoF2B8ndzzLndjqMy/2PgEeNLN35VA74D/vg1wCozcmH2h5h9OYbcF+AHnW/VNOO167wHr3J/N3LS9gWdjjv25ey2WAGMDiq0Ep+2i8hqs7FXZFpiT7FoIMP9ecK+vFTiFRpuqMbrPq33eg4jP3f9c5XUXkzaUPKyrh00VY4wxxhdWRWaMMcYXVsAYY4zxhRUwxhhjfGEFjDHGGF9YAWOMMcYXVsAY4wMRqagyU3OdzcwrIh1jZ+I1JlVlhR2AMSeo71S1R9hBGBMmu4MxJkDueh4Pisin7qOLuz9PRN5zJ2N8T0Qi7v5W7hory91HP/etMkXkGXHWAZovIjlu+t+IyCr3ff4c0q9pDGAFjDF+yalSRXZVzGv7VLUP8AdgqrvvDzjLFnTHmSzycXf/48BCdSbb7IUzghugK/Ckqp4J7AEK3f33Aj3d97nVr1/OGC9sJL8xPhCRA6raKM7+jcBAVd3gTlS6VVWbi0g5zvQlP7j7t6hqCxHZAbRX1UMx79ERZ92Xru7ze4BsVX1AROYCB3BmfX5T3Yk6jQmD3cEYEzxNsJ0oTTyHYrYr+Ed76mU4c7udA3zmztBrTCisgDEmeFfF/PzE3f4YZ/ZegGuBj9zt94BfAYhIpoicnOhNRSQD6KCqHwD/ATQBqt1FGRMU+3ZjjD9yRGRZzPO5qlrZVbm+iBTjfMG72t33G2C6iNwN7ADGuvvHAU+LyE04dyq/wpmJN55M4EURycWZpfpRVd1TZ7+RMcfI2mCMCZDbBtNbVcvDjsUYv1kVmTHGGF/YHYwxxhhf2B2MMcYYX1gBY4wxxhdWwBhjjPGFFTDGGGN8YQWMMcYYX/w/aH0EMgeNwwEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your code here\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot(avg_batch_running_duration_CPU, color = 'g')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average batch running duration time in CPU')\n",
    "plt.title('Epochs vs Average batch running duration time in CPU')\n",
    "plt.figure(2)\n",
    "plt.plot(avg_batch_running_duration_GPU, color = 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average batch running duration time in GPU')\n",
    "plt.title('Epochs vs Average batch running duration time in GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>Do you want to use GPU in production?</h2>\n",
    "\n",
    "<p>Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The <a href=\"https://cocl.us/ML0122EN_IBMCLOUD_PowerAI\">PowerAI platform on IBM Cloud</a> supports popular machine learning libraries and dependencies including TensorFlow, Caffe, PyTorch, and Theano.</p>\n",
    "\n",
    "<h3>Thanks for completing this lesson!</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h4>Author:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>,   <a href=\"https://www.linkedin.com/in/yi-leng-yao-84451275/\">Yi leng Yao</a></h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
